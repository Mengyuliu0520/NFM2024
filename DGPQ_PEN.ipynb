{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "983c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import cos, sin\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "from typing import Optional\n",
    "from control.matlab import ss, lsim, linspace, c2d\n",
    "from functools import partial\n",
    "import math\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "990103c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a5e4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_normalize(x):\n",
    "    return ((x + np.pi) % (2 * np.pi)) - np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d595d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pend1(gym.Env):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None, g=10.0):\n",
    "        super(Pend1, self).__init__()\n",
    "        self.max_speed = 8\n",
    "        self.max_torque = 2.0\n",
    "        self.dt = 0.05\n",
    "        self.g = g\n",
    "        self.m = 1.0\n",
    "        self.l = 1.0\n",
    "        self.center = np.array([1,0,0])\n",
    "        self.obstacle = np.array([0,1,3])\n",
    "        self.render_mode = render_mode\n",
    "        self.screen_dim = 500\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.isopen = True\n",
    "\n",
    "        high = np.array([1.0, 1.0, self.max_speed], dtype=np.float32)\n",
    "        # This will throw a warning in tests/envs/test_envs in utils/env_checker.py as the space is not symmetric\n",
    "        #   or normalised as max_torque == 2 by default. Ignoring the issue here as the default settings are too old\n",
    "        #   to update to follow the openai gym api\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-self.max_torque, high=self.max_torque, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low=-high, high=high, dtype=np.float32)\n",
    "        # store current trace\n",
    "        self.cache1 = []\n",
    "        self.cache2 = []\n",
    "        self.cache3 = []\n",
    "        # ball radius\n",
    "        self.target_norm_radius = 0.3 # norm ball radius of target, tune this\n",
    "        self.safe_norm_radius = 0.1 # norm ball radius of safe, tune this\n",
    "        self.total_time = 120\n",
    "        # step number\n",
    "        self.steps = 0\n",
    "        self.u_lowbound = None\n",
    "        self.caches = []\n",
    "        self.reward_cache = [] # cache distances to target norm ball center\n",
    "#         self.avoid_reward_cache = [] # cache distances to obstacles norm ball center\n",
    "        self.final_reward_cache = [] # cache final reward\n",
    "        # How long should this trace be, i.e. deadline\n",
    "        self.step_const = random.randint(10, 50)\n",
    "        # Maximum reward from each trace\n",
    "        self.max_reward_list = []\n",
    "        self.quality_list = []\n",
    "        self.total_steps = 0\n",
    "        self.step_history = []\n",
    "        self.reached = False\n",
    "    def angle_normalize(x):\n",
    "        return ((x + np.pi) % (2 * np.pi)) - np.pi\n",
    "    def step(self, u):\n",
    "        th, thdot = self.state  # th := theta\n",
    "        g = self.g\n",
    "        m = self.m\n",
    "        l = self.l\n",
    "        dt = self.dt\n",
    "        # simulate next step and get measurement\n",
    "        self.steps += 1\n",
    "        self.total_steps += 1\n",
    "        terminated = False\n",
    "        u = np.clip(u, -self.max_torque, self.max_torque)[0]\n",
    "        self.last_u = u\n",
    "        costs = 1\n",
    "        self.last_u = u  # for rendering\n",
    "        costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (u**2)\n",
    "                                        \n",
    "        newthdot = thdot + (3 * g / (2 * l) * np.sin(th) + 3.0 / (m * l**2) * u) * dt\n",
    "        newthdot = np.clip(newthdot, -self.max_speed, self.max_speed)\n",
    "        newth = th + newthdot * dt\n",
    "\n",
    "        self.state = np.array([newth, newthdot])\n",
    "\n",
    "        # calculate euclidean distance and update reward cache\n",
    "        dist = np.linalg.norm(self._get_obs() - self.center)\n",
    "        obs_dist = np.linalg.norm(self._get_obs() - self.obstacle)\n",
    "        reward = self.target_norm_radius - dist\n",
    "#         obs_reward = obs_dist-self.safe_norm_radius\n",
    "\n",
    "        self.reward_cache.append(reward)\n",
    "#         self.avoid_reward_cache.append(obs_reward)\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "        if self.steps < 10:\n",
    "            reach_reward = max(self.reward_cache)\n",
    "        else:\n",
    "            reach_reward = max(self.reward_cache[-10:])\n",
    "#         self.avoid_reward_cache.append(obs_reward)\n",
    "        # quantitative semantics\n",
    "        # reach reward, encourage reaching target\n",
    "#         if self.steps < 10:\n",
    "#             reach_reward = max(self.reward_cache)\n",
    "#         else:\n",
    "#             reach_reward = max(self.reward_cache[-10:])\n",
    "#         if self.steps < 10:\n",
    "#             avoid_reward = min(self.avoid_reward_cache)\n",
    "#         else:\n",
    "#             avoid_reward = min(self.avoid_reward_cache[-10:])\n",
    "\n",
    "#         # very strict reward, always within target\n",
    "#         strict_avoid_reward = avoid_reward - 0.5 * self.safe_norm_radius # half safe norm radius\n",
    "#         strict_reach_reward = reach_reward - 0.5 * self.target_norm_radius # half target norm radius\n",
    "\n",
    "        # overall reward, pick one of the final_reward\n",
    "#         final_reward = reach_reward\n",
    "#         final_reward = approach_reward\n",
    "#         final_reward = min(reach_reward, avoid_reward) # reach and avoid\n",
    "#         final_reward = min(approach_reward, avoid_reward) # approach and avoid\n",
    "#         final_reward = min(reach_reward, approach_reward) # reach and approach\n",
    "#         deadline_reward = (self.last_dist-dist)/(self.step_const - self.steps+1)\n",
    "        final_reward = reach_reward\n",
    "        # split cases: if already inside target, give very large constant reward for maintaining\n",
    "        if dist <= self.target_norm_radius:\n",
    "            final_reward = 10 # this gives 39/50 sucess with reach+approach+avoid\n",
    "\n",
    "        self.final_reward_cache.append(final_reward)\n",
    "\n",
    "        # If this is the last step, reset the state\n",
    "        if self.steps == self.step_const or obs_dist<=self.safe_norm_radius:\n",
    "            self.max_reward_list.append(max(self.final_reward_cache)) # use max final reward to measure episodes\n",
    "            self.step_history.append(self.total_steps)\n",
    "            self.quality_list.append(sum(self.final_reward_cache))\n",
    "            terminated = True\n",
    "            self.reset()\n",
    "\n",
    "#         # If within target norm ball, early terminate\n",
    "#         if dist <= self.target_norm_radius:\n",
    "#             terminated = True\n",
    "#             self.reset()\n",
    "\n",
    "        # Return next state, reward, done, info\n",
    "        return self._get_obs(), final_reward, terminated, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([math.pi/3, -1])\n",
    "        self.reward_cache = []\n",
    "        self.final_reward_cache = []\n",
    "        self.steps=0\n",
    "        self.caches.append(self.cache1)\n",
    "        self.caches.append(self.cache2)\n",
    "        self.caches.append(self.cache3)\n",
    "        self.cache1 = []\n",
    "        self.cache2 = []\n",
    "        self.cache3 = []\n",
    "        # random # of steps for this trace\n",
    "#         self.step_const = random.randint(10, 50) # deadline range\n",
    "        self.step_const = 500\n",
    "        self.reached = False\n",
    "        return self._get_obs() # return something matching shape\n",
    "\n",
    "    def _get_obs(self):\n",
    "        theta, thetadot = self.state\n",
    "        return np.array([np.cos(theta), np.sin(theta), thetadot], dtype=np.float32)\n",
    "\n",
    "    def render(self):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            import pygame\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.isopen = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed2d29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#settings\n",
    "target_norm_radius = 0.3 # norm ball radius of target, tune this\n",
    "safe_norm_radius = 0.1\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "num_epi= 200\n",
    "num_steps = 200\n",
    "action_list = [-1,1]\n",
    "delta_tolerance = 0.5\n",
    "discount = 0.9\n",
    "center = np.array([1, 0, 0])\n",
    "obstacles = np.array([0, 1, 3])\n",
    "rmax = target_norm_radius\n",
    "mean_offset = target_norm_radius/(1-discount)\n",
    "# initial the env\n",
    "env = Pend1()\n",
    "state = env.reset()\n",
    "lpschitz = 2\n",
    "#Initial data collection\n",
    "initial_buffer = 50\n",
    "epsilon = 0.05\n",
    "data_buffer = [[],[]]\n",
    "for i in range(initial_buffer):\n",
    "    this_action = random.randint(0,1)\n",
    "    new_state, reward, done, _= env.step([action_list[this_action]])\n",
    "    data_buffer[this_action].append((state, reward))\n",
    "    state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee3e628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_1 = np.array([tuple[0] for tuple in data_buffer[0]])\n",
    "trainx_2 = np.array([tuple[0] for tuple in data_buffer[1]])\n",
    "trainy_1 = np.array([tuple[1] for tuple in data_buffer[0]])\n",
    "trainy_2 = np.array([tuple[1] for tuple in data_buffer[1]])\n",
    "train_x_list = [trainx_1, trainx_2]\n",
    "train_y_list = [trainy_1, trainy_2]\n",
    "x_scaler_list = []\n",
    "for i in range(len(action_list)):\n",
    "    x_scaler = StandardScaler()\n",
    "    train_x_list[i] = x_scaler.fit_transform(train_x_list[i])\n",
    "    x_scaler_list.append(x_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c48ae3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpc1 = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "gpc2 = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "reward_q1 = []\n",
    "reward_q2 = []\n",
    "gpclist = [gpc1,gpc2]\n",
    "reward_q_list = [reward_q1,reward_q2]\n",
    "i = 0\n",
    "for i in range(len(action_list)):\n",
    "    gpclist[i].fit(train_x_list[i], train_y_list[i])\n",
    "results = [0]*2\n",
    "new_results = [0]*2\n",
    "std_list_1 = [0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a5df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in range(num_epi):\n",
    "    print(i)\n",
    "    for j in range(num_steps):\n",
    "        # max q_st\n",
    "        for k in range(len(reward_q_list)):\n",
    "            state_entry = state.reshape(1,-1)\n",
    "            state_entry_scale = x_scaler_list[k].transform(state_entry)\n",
    "            if reward_q_list[k] == []:\n",
    "                results[k], std_list_1[k] = gpclist[k].predict(state_entry_scale, return_std=True)\n",
    "            else:\n",
    "                lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - state_entry) for point in reward_q_list[k]]\n",
    "                results[k], std_list_1[k] = gpclist[k].predict(state_entry_scale, return_std=True)\n",
    "                results[k] = min(min(lp_values), results[k])\n",
    "                \n",
    "#         if reward_q1 == []:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             value_result1, std1 = gpc1.predict(state_entry, return_std=True)\n",
    "#         else:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - state_entry) for point in reward_q1]\n",
    "#             value_result1, std1 = gpc1.predict(state_entry, return_std=True)\n",
    "#             value_result1 = min(min(lp_values), value_result1)\n",
    "#         if reward_q2 == []:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             value_result2, std2 = gpc2.predict(state_entry, return_std=True)\n",
    "#         else:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - state_entry) for point in reward_q2]\n",
    "#             value_result2, std2 = gpc2.predict(state_entry, return_std=True)\n",
    "#             value_result2 = min(min(lp_values), value_result2)        \n",
    "#         if reward_q3 == []:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             value_result3, std3 = gpc3.predict(state_entry, return_std=True)\n",
    "#         else:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - state_entry) for point in reward_q3]\n",
    "#             value_result3, std3 = gpc3.predict(state_entry, return_std=True)\n",
    "#             value_result3 = min(min(lp_values), value_result3)        \n",
    "#         if reward_q4 == []:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             value_result4, std4 = gpc4.predict(state_entry, return_std=True)\n",
    "#         else:\n",
    "#             state_entry = state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - state_entry) for point in reward_q4]\n",
    "#             value_result4, std4 = gpc4.predict(state_entry, return_std=True)\n",
    "#             value_result4 = min(min(lp_values), value_result4)\n",
    "        # get actions\n",
    "        # get new values\n",
    "#         results = np.array([value_result1, value_result2, value_result3, value_result4])\n",
    "#         results = np.array([x+mean_offset for x in results])\n",
    "        which_action = action_list[np.argmax(results)]\n",
    "        new_state, reward, done, _ = env.step([which_action])\n",
    "        k = 0\n",
    "        for k in range(len(reward_q_list)):\n",
    "            new_state_entry = new_state.reshape(1,-1)\n",
    "            new_state_entry_scale = x_scaler_list[k].transform(new_state_entry)\n",
    "            if reward_q_list[k] == []:\n",
    "                new_results[k], std_list_1[k] = gpclist[k].predict(new_state_entry_scale, return_std=True)\n",
    "            else:\n",
    "                lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - new_state_entry) for point in reward_q_list[k]]\n",
    "                new_results[k], std_list_1[k] = gpclist[k].predict(new_state_entry_scale, return_std=True)\n",
    "                new_results[k] = min(min(lp_values), new_results[k])\n",
    "                \n",
    "        \n",
    "#         if reward_q1 == []:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             new_value_result1 = gpc1.predict(new_state_entry)[0]\n",
    "#         else:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - new_state_entry) for point in reward_q1]\n",
    "#             new_value_result1 = gpc1.predict(new_state_entry)[0]\n",
    "#             new_value_result1 = min(min(lp_values), new_value_result1)\n",
    "#         if reward_q2 == []:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             new_value_result2 = gpc2.predict(new_state_entry)[0]\n",
    "#         else:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - new_state_entry) for point in reward_q2]\n",
    "#             new_value_result2 = gpc2.predict(new_state_entry)[0]\n",
    "#             new_value_result2 = min(min(lp_values), new_value_result2)        \n",
    "#         if reward_q3 == []:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             new_value_result3 = gpc3.predict(new_state_entry)[0]\n",
    "#         else:\n",
    "#             new_state_entry = new_state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - new_state_entry) for point in reward_q3]\n",
    "#             new_value_result3 = gpc3.predict(new_state_entry)[0]\n",
    "#             new_value_result3 = min(min(lp_values), new_value_result3)        \n",
    "#         if reward_q4 == []:\n",
    "#             new_state_entry = state.reshape(1,-1)\n",
    "#             new_value_result4 = gpc4.predict(new_state_entry)[0]\n",
    "#         else:\n",
    "#             new_state_entry = state.reshape(1,-1)\n",
    "#             lp_values = [point[1]+lpschitz*np.linalg.norm(point[0] - new_state_entry) for point in reward_q4]\n",
    "#             new_value_result4 = gpc4.predict(new_state_entry)[0]\n",
    "#             new_value_result4 = min(min(lp_values), new_value_result4)\n",
    "#         # get the q value\n",
    "#         new_results = np.array([new_value_result1, new_value_result2, new_value_result3, new_value_result4])\n",
    "#         new_results = np.array([x+mean_offset for x in new_results])\n",
    "        \n",
    "        q_value = reward+discount*max(new_results)\n",
    "        action_index = np.argmax(results)\n",
    "        var1 = std_list_1[action_index]**2\n",
    "#         if which_action == -10:\n",
    "#             var1 = std1*std1\n",
    "#         elif which_action == -5:\n",
    "#             var1 = std2*std2\n",
    "#         elif which_action == 5:\n",
    "#             var1 = std3*std3\n",
    "#         else:\n",
    "#             var1 = std4*std4\n",
    "        if var1>delta_tolerance:\n",
    "            if isinstance(q_value, np.ndarray):\n",
    "                q_value = q_value[0]\n",
    "            train_x_list[action_index] = np.vstack([train_x_list[action_index], state_entry])\n",
    "            train_y_list[action_index] = np.concatenate([train_y_list[action_index], [q_value]])\n",
    "            x_scaler = StandardScaler()\n",
    "            train_x_list[action_index] = x_scaler.fit_transform(train_x_list[action_index])\n",
    "            x_scaler_list[action_index] = x_scaler\n",
    "            gpclist[action_index].fit(train_x_list[action_index], train_y_list[action_index])\n",
    "        state_entry_new_scale = x_scaler_list[action_index].transform(state_entry)\n",
    "        useless_result,update_std = gpclist[action_index].predict(state_entry_new_scale, return_std=True)\n",
    "        var2 = update_std*update_std\n",
    "        if (var1>delta_tolerance) and delta_tolerance > var2 and(results[action_index]-useless_result)>2*epsilon:\n",
    "            reward_q_list[action_index].append((state, useless_result+epsilon))\n",
    "            for k in range(len(action_list)):\n",
    "                gpclist[k] = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "                train_x_list[k] = train_x_list[k][:2]\n",
    "                train_y_list[k] = train_y_list[k][:2]\n",
    "        state= new_state\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Test 50 traces\n",
    "env = Pend1()\n",
    "state = env.reset()\n",
    "dims0 = []\n",
    "dims1 = []\n",
    "dims2 = []\n",
    "euclids = []\n",
    "center = np.array([1, 0, 0])\n",
    "obstacle = np.array([0, 1, 3])\n",
    "num_reached = 0\n",
    "unsafe = 0\n",
    "time = 0\n",
    "stay = 0\n",
    "for i in range(len(action_list)):\n",
    "    reward_q_list[i].append((np.array([0,0,0]), np.array([-5])))\n",
    "for j in range(50):\n",
    "    dim0 = []\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    euclid = []\n",
    "    state = env.reset()\n",
    "    flag = 0\n",
    "    # Print initial state\n",
    "    for i in range(50):\n",
    "        q1_euclids = np.array([np.linalg.norm(state[:3]-x[0])for x in reward_q1])\n",
    "        q2_euclids = np.array([np.linalg.norm(state[:3]-x[0])for x in reward_q2])\n",
    "        close_1 = np.argmin(q1_euclids)\n",
    "        close_2 = np.argmin(q2_euclids)\n",
    "        close_value_list = np.array([reward_q_list[0][close_1][1],reward_q_list[1][close_2][1]])\n",
    "        action = [action_list[np.argmin(close_value_list)]]\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        dim0.append(state[0])\n",
    "        dim1.append(state[1])\n",
    "        dim2.append(state[2])\n",
    "        dist = np.linalg.norm(state[:3]-center)\n",
    "        obs_dist = np.linalg.norm(state[:3]-obstacle)\n",
    "        euclid.append(dist)\n",
    "        state = new_state\n",
    "        if obs_dist <= 0.1:\n",
    "            unsafe+=1\n",
    "            time+=50\n",
    "            break\n",
    "        if dist <= 0.2: # stop\n",
    "            if flag == 0:\n",
    "                num_reached += 1\n",
    "                time+=i\n",
    "                flag = 1\n",
    "            else:\n",
    "                if i == 49:\n",
    "                    stay+=1\n",
    "                continue\n",
    "    dims0.append(dim0)\n",
    "    dims1.append(dim1)\n",
    "    dims2.append(dim2)\n",
    "    euclids.append(euclid)\n",
    "ref= [math.pi/2]*100\n",
    "time+=(1000-num_reached-unsafe)*50\n",
    "print(\"Total number reached = \" + str(num_reached))\n",
    "print(\"Total number collison = \" + str(unsafe))\n",
    "print(\"Total number Stay = \" + str(stay))\n",
    "print(\"Average reach time = \" + str(time/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reward_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ecf2898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([0.03004481, 0.99954855, 3.664704  ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([-0.18214642,  0.9832714 ,  4.2643657 ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-0.74884297])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.16891725, 0.9856302 , 2.6015127 ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([0.01019409, 0.999948  , 3.1907353 ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([-0.40160978,  0.9158109 ,  4.6786675 ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([-0.03174179,  0.9994961 ,  3.9835198 ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-0.71593949])),\n",
       "  (array([-0.17889006,  0.9838691 ,  4.546401  ], dtype=float32),\n",
       "   array([-1.33533447])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-0.80340665])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-0.89809482])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-0.88430923])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-0.86586368])),\n",
       "  (array([0.33237305, 0.943148  , 1.8266664 ], dtype=float32),\n",
       "   array([-0.84568615])),\n",
       "  (array([0.217856  , 0.97598094, 2.3840275 ], dtype=float32),\n",
       "   array([-1.4053269])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-1.3139059])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-0.88006661])),\n",
       "  (array([0.14576967, 0.98931855, 3.279267  ], dtype=float32),\n",
       "   array([-0.91459859])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-1.09173353])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-1.06082857])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-1.10539452])),\n",
       "  (array([0.10564407, 0.994404  , 3.052821  ], dtype=float32),\n",
       "   array([-1.06258385])),\n",
       "  (array([-0.07651477,  0.99706846,  3.648624  ], dtype=float32),\n",
       "   array([-1.18414569])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.29498561])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-1.32181795])),\n",
       "  (array([-0.13411775,  0.9909654 ,  4.2423444 ], dtype=float32),\n",
       "   array([-1.79232843])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-1.20767208])),\n",
       "  (array([0.19632733, 0.9805384 , 2.790366  ], dtype=float32),\n",
       "   array([-1.21096328])),\n",
       "  (array([0.02881846, 0.9995847 , 3.3757699 ], dtype=float32),\n",
       "   array([-1.74184772])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-1.54090291])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-1.43047961])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-1.41547601])),\n",
       "  (array([-5.4099795e-04,  9.9999988e-01,  3.8534408e+00], dtype=float32),\n",
       "   array([-1.82881643])),\n",
       "  (array([-0.22136408,  0.97519124,  4.4534407 ], dtype=float32),\n",
       "   array([-2.01466032])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-1.4634308])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.03627462])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-1.50054118])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-1.53173691])),\n",
       "  (array([0.22049591, 0.9753879 , 2.6634047 ], dtype=float32),\n",
       "   array([-1.95340148])),\n",
       "  (array([0.06003944, 0.998196  , 3.2449458 ], dtype=float32),\n",
       "   array([-2.03647672])),\n",
       "  (array([-0.13172016,  0.99128693,  3.8435926 ], dtype=float32),\n",
       "   array([-1.87838572])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.81985018])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-1.62202522])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-1.51572882])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-1.61238709])),\n",
       "  (array([-0.2661688 ,  0.96392643,  4.5267944 ], dtype=float32),\n",
       "   array([-2.30555238])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-1.75817284])),\n",
       "  (array([0.03004481, 0.99954855, 3.664704  ], dtype=float32),\n",
       "   array([-2.23915952])),\n",
       "  (array([-0.18214642,  0.9832714 ,  4.2643657 ], dtype=float32),\n",
       "   array([-2.4883353])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-1.92269354])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-1.97091135])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-1.6628389])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-1.81642536])),\n",
       "  (array([0.2511526, 0.9679475, 2.3486016], dtype=float32),\n",
       "   array([-1.87766617])),\n",
       "  (array([0.10743497, 0.9942121 , 2.9245622 ], dtype=float32),\n",
       "   array([-2.32845911])),\n",
       "  (array([-0.0683151,  0.9976638,  3.5202212], dtype=float32),\n",
       "   array([-2.37379544])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.0903346])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-1.98879756])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-2.05049462])),\n",
       "  (array([0.30371347, 0.95276344, 2.131281  ], dtype=float32),\n",
       "   array([-2.27901333])),\n",
       "  (array([-0.00543258,  0.9999852 ,  3.5845551 ], dtype=float32),\n",
       "   array([-2.73650824])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.47926716])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-2.3394462])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-2.09513307])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-2.22838282])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-2.27778224])),\n",
       "  (array([0.23510137, 0.97197086, 2.3634048 ], dtype=float32),\n",
       "   array([-2.55031664])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-2.66782836])),\n",
       "  (array([-0.24344668,  0.96991426,  4.5834146 ], dtype=float32),\n",
       "   array([-2.70201267])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-2.30058124])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-2.43671204])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-2.62957313])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-2.41345812])),\n",
       "  (array([0.13785754, 0.99045205, 2.734651  ], dtype=float32),\n",
       "   array([-2.2618277])),\n",
       "  (array([-0.237155  ,  0.97147185,  4.2271943 ], dtype=float32),\n",
       "   array([-2.70201267])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-2.34597521])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-2.65464083])),\n",
       "  (array([0.06013621, 0.99819016, 3.3622406 ], dtype=float32),\n",
       "   array([-2.5801773])),\n",
       "  (array([-0.13743526,  0.99051076,  3.9608831 ], dtype=float32),\n",
       "   array([-2.36413787])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.54825675])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-2.52024382])),\n",
       "  (array([0.2893884, 0.9572118, 2.4312809], dtype=float32),\n",
       "   array([-2.86746823])),\n",
       "  (array([-0.05092298,  0.9987026 ,  3.891467  ], dtype=float32),\n",
       "   array([-2.93856063])),\n",
       "  (array([-0.27199897,  0.96229756,  4.490494  ], dtype=float32),\n",
       "   array([-2.97569199])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.85434454])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-2.40166791])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-2.55417934])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-2.60656579])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-2.77131806])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-2.46008245])),\n",
       "  (array([0.15411435, 0.988053  , 2.9015126 ], dtype=float32),\n",
       "   array([-2.83192296])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-2.91123001])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-2.75704845])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-3.02799162])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-2.83348812])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-2.90830273])),\n",
       "  (array([0.13785754, 0.99045205, 2.734651  ], dtype=float32),\n",
       "   array([-2.81286311])),\n",
       "  (array([-0.02807285,  0.9996059 ,  3.32749   ], dtype=float32),\n",
       "   array([-2.76561531])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-2.90016362])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-2.91641789])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-2.85191106])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.91034409])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-2.80020509])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-3.12057052])),\n",
       "  (array([0.31954974, 0.9475695 , 2.115075  ], dtype=float32),\n",
       "   array([-3.01660693])),\n",
       "  (array([0.19029896, 0.98172617, 2.6757522 ], dtype=float32),\n",
       "   array([-2.96135454])),\n",
       "  (array([0.02836051, 0.9995978 , 3.2620468 ], dtype=float32),\n",
       "   array([-3.06098636])),\n",
       "  (array([-0.16397904,  0.98646384,  3.861745  ], dtype=float32),\n",
       "   array([-3.06678322])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.97380382])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-3.21364651])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-3.04506701])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-3.02297557])),\n",
       "  (array([0.33237305, 0.943148  , 1.8266664 ], dtype=float32),\n",
       "   array([-2.94207348])),\n",
       "  (array([-0.15134092,  0.98848164,  4.164824  ], dtype=float32),\n",
       "   array([-3.35868436])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.26902755])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-2.97945501])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-2.94369039])),\n",
       "  (array([0.2071596, 0.9783072, 2.9526045], dtype=float32),\n",
       "   array([-2.98098912])),\n",
       "  (array([0.03184854, 0.9994927 , 3.536335  ], dtype=float32),\n",
       "   array([-3.05380357])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-3.11856435])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-3.06169512])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-3.48982328])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.30849119])),\n",
       "  (array([0.04744404, 0.9988739 , 3.647246  ], dtype=float32),\n",
       "   array([-3.53551859])),\n",
       "  (array([-0.16411246,  0.9864416 ,  4.2464013 ], dtype=float32),\n",
       "   array([-3.6035006])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.43035248])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.23889757])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-3.31345437])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-3.23365623])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-3.29427348])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.35734179])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-3.09404288])),\n",
       "  (array([0.07562959, 0.997136  , 3.355615  ], dtype=float32),\n",
       "   array([-3.37162431])),\n",
       "  (array([-0.12166926,  0.9925707 ,  3.953467  ], dtype=float32),\n",
       "   array([-3.26852454])),\n",
       "  (array([-0.34230238,  0.93958986,  4.547895  ], dtype=float32),\n",
       "   array([-3.74869304])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.66385078])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.42203628])),\n",
       "  (array([0.34880987, 0.9371935 , 2.0997095 ], dtype=float32),\n",
       "   array([-3.30907274])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.52422604])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-3.36271073])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-3.31135838])),\n",
       "  (array([0.13921139, 0.9902627 , 3.0218894 ], dtype=float32),\n",
       "   array([-3.42560083])),\n",
       "  (array([-0.26360938,  0.96462953,  4.513954  ], dtype=float32),\n",
       "   array([-3.9364919])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-3.71061555])),\n",
       "  (array([-0.01674634,  0.99985975,  3.6835198 ], dtype=float32),\n",
       "   array([-3.7842625])),\n",
       "  (array([-0.22887112,  0.97345674,  4.283415  ], dtype=float32),\n",
       "   array([-3.9364919])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-3.61263893])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-3.45433795])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-3.3519666])),\n",
       "  (array([0.13785754, 0.99045205, 2.734651  ], dtype=float32),\n",
       "   array([-3.50237912])),\n",
       "  (array([-0.02807285,  0.9996059 ,  3.32749   ], dtype=float32),\n",
       "   array([-3.49629192])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.63292316])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-3.54082754])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-3.3547551])),\n",
       "  (array([0.22049591, 0.9753879 , 2.6634047 ], dtype=float32),\n",
       "   array([-3.63405633])),\n",
       "  (array([0.06003944, 0.998196  , 3.2449458 ], dtype=float32),\n",
       "   array([-3.67859646])),\n",
       "  (array([-0.13172016,  0.99128693,  3.8435926 ], dtype=float32),\n",
       "   array([-3.77053063])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-3.69975878])),\n",
       "  (array([0.12827393, 0.9917388 , 3.2991898 ], dtype=float32),\n",
       "   array([-3.92724341])),\n",
       "  (array([-0.0659734,  0.9978214,  3.8929937], dtype=float32),\n",
       "   array([-4.064845])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.01847381])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.70768035])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.6157428])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-3.5018187])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-3.47805282])),\n",
       "  (array([0.26633695, 0.96388   , 2.3392868 ], dtype=float32),\n",
       "   array([-3.32150542])),\n",
       "  (array([-0.29702985,  0.9548682 ,  4.70479   ], dtype=float32),\n",
       "   array([-4.07770902])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.73648494])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-3.73055134])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-3.83954464])),\n",
       "  (array([0.09246185, 0.9957162 , 3.044601  ], dtype=float32),\n",
       "   array([-3.91594634])),\n",
       "  (array([-0.08935597,  0.99599975,  3.6413882 ], dtype=float32),\n",
       "   array([-3.82425069])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.84377944])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-3.72904869])),\n",
       "  (array([-0.16735658,  0.9858964 ,  4.263943  ], dtype=float32),\n",
       "   array([-4.16415668])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-3.95653119])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-3.93307166])),\n",
       "  (array([0.04392288, 0.99903494, 3.3734784 ], dtype=float32),\n",
       "   array([-4.07441574])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-3.87370875])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.92308116])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-3.80041731])),\n",
       "  (array([0.25711006, 0.96638215, 2.4628384 ], dtype=float32),\n",
       "   array([-3.88347242])),\n",
       "  (array([-0.08839735,  0.9960853 ,  3.9332433 ], dtype=float32),\n",
       "   array([-4.11249616])),\n",
       "  (array([-0.30984333,  0.9507876 ,  4.5303073 ], dtype=float32),\n",
       "   array([-4.2398306])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-4.06721206])),\n",
       "  (array([-0.01674634,  0.99985975,  3.6835198 ], dtype=float32),\n",
       "   array([-4.21097285])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-3.83957044])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-4.00500519])),\n",
       "  (array([0.31818897, 0.9480273 , 2.1266663 ], dtype=float32),\n",
       "   array([-3.87932721])),\n",
       "  (array([0.18830325, 0.9821109 , 2.687687  ], dtype=float32),\n",
       "   array([-4.16767474])),\n",
       "  (array([0.02571786, 0.99966925, 3.27427   ], dtype=float32),\n",
       "   array([-4.2051446])),\n",
       "  (array([-0.16719152,  0.9859244 ,  3.874022  ], dtype=float32),\n",
       "   array([-4.13978588])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.08575528])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.87680866])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-4.03816375])),\n",
       "  (array([0.1755522, 0.9844701, 2.9757524], dtype=float32),\n",
       "   array([-4.05987189])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.08755758])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.07276451])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-4.07627828])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-4.12995864])),\n",
       "  (array([-0.02597892,  0.9996625 ,  3.612937  ], dtype=float32),\n",
       "   array([-4.25518153])),\n",
       "  (array([-0.2344143,  0.9721368,  4.2126837], dtype=float32),\n",
       "   array([-4.33855556])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.23797076])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.9636302])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.96206307])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-3.88312334])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-4.08444616])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-4.13770995])),\n",
       "  (array([0.13911627, 0.99027604, 2.9047544 ], dtype=float32),\n",
       "   array([-4.2489791])),\n",
       "  (array([-0.03529679,  0.9993769 ,  3.4974616 ], dtype=float32),\n",
       "   array([-4.17229911])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.96742498])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-4.31242987])),\n",
       "  (array([0.0450341 , 0.99898547, 3.3647041 ], dtype=float32),\n",
       "   array([-4.23384107])),\n",
       "  (array([-0.15254986,  0.9882958 ,  3.9639432 ], dtype=float32),\n",
       "   array([-4.35050233])),\n",
       "  (array([-0.37176177,  0.92832816,  4.5551653 ], dtype=float32),\n",
       "   array([-4.43430977])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.18285156])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-4.30106684])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-4.20399887])),\n",
       "  (array([0.1229858 , 0.99240845, 3.034651  ], dtype=float32),\n",
       "   array([-4.31548143])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.31611015])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.10790373])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-4.16041266])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-4.06036312])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-4.08533848])),\n",
       "  (array([-0.13142811,  0.9913257 ,  4.140263  ], dtype=float32),\n",
       "   array([-4.51234683])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-4.39719705])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-4.2623902])),\n",
       "  (array([0.31818897, 0.9480273 , 2.1266663 ], dtype=float32),\n",
       "   array([-4.43316819])),\n",
       "  (array([0.18830325, 0.9821109 , 2.687687  ], dtype=float32),\n",
       "   array([-4.44928651])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.44595632])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.19370446])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-4.20874712])),\n",
       "  (array([0.06246484, 0.9980472 , 3.5273058 ], dtype=float32),\n",
       "   array([-4.62613773])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.2685805])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-4.22297031])),\n",
       "  (array([-0.1522769,  0.9883379,  4.2608833], dtype=float32),\n",
       "   array([-4.56753567])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.37212495])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-4.25611985])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-4.44375904])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.43328595])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-4.58909352])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-4.6447238])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-4.46466244])),\n",
       "  (array([-0.24344668,  0.96991426,  4.5834146 ], dtype=float32),\n",
       "   array([-4.6447238])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.58942153])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.45745855])),\n",
       "  (array([0.10928905, 0.99401003, 3.3250337 ], dtype=float32),\n",
       "   array([-4.4337143])),\n",
       "  (array([-0.08641137,  0.99625957,  3.9205413 ], dtype=float32),\n",
       "   array([-4.63609942])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.52317698])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.41047309])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-4.40359366])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-4.47957589])),\n",
       "  (array([-0.17620878,  0.9843528 ,  4.444184  ], dtype=float32),\n",
       "   array([-4.69870698])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.63532859])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-4.52787082])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-4.4692516])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.50310949])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.5793962])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-4.50197414])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-4.46968377])),\n",
       "  (array([-0.06148719,  0.99810785,  3.6473517 ], dtype=float32),\n",
       "   array([-4.55292086])),\n",
       "  (array([-0.2704136 ,  0.96274424,  4.2459326 ], dtype=float32),\n",
       "   array([-4.83317154])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.71826874])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.45546208])),\n",
       "  (array([0.34880987, 0.9371935 , 2.0997095 ], dtype=float32),\n",
       "   array([-4.52301858])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-4.48276823])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-4.54804494])),\n",
       "  (array([0.01335037, 0.9999109 , 3.381562  ], dtype=float32),\n",
       "   array([-4.62434591])),\n",
       "  (array([-0.18465811,  0.9828028 ,  3.9814951 ], dtype=float32),\n",
       "   array([-4.58771184])),\n",
       "  (array([-0.40241545,  0.9154571 ,  4.5685973 ], dtype=float32),\n",
       "   array([-4.87035151])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.61720834])),\n",
       "  (array([-0.19687444,  0.9804287 ,  4.5643654 ], dtype=float32),\n",
       "   array([-4.90781768])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.61895494])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-4.63290494])),\n",
       "  (array([0.1755522, 0.9844701, 2.9757524], dtype=float32),\n",
       "   array([-4.65812239])),\n",
       "  (array([-1.7385861e-03,  9.9999851e-01,  3.5641048e+00], dtype=float32),\n",
       "   array([-4.68621942])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.90590241])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.5709132])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-4.42407671])),\n",
       "  (array([0.10876528, 0.99406743, 3.2121968 ], dtype=float32),\n",
       "   array([-4.59709964])),\n",
       "  (array([-0.08131661,  0.9966883 ,  3.8077474 ], dtype=float32),\n",
       "   array([-4.70328044])),\n",
       "  (array([-0.29711488,  0.95484173,  4.4052634 ], dtype=float32),\n",
       "   array([-4.93653566])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.70485593])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-4.68464024])),\n",
       "  (array([-0.13411775,  0.9909654 ,  4.2423444 ], dtype=float32),\n",
       "   array([-4.97006377])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.56041322])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-4.61514051])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-4.68762197])),\n",
       "  (array([0.18438931, 0.9828533 , 2.710622  ], dtype=float32),\n",
       "   array([-4.67188946])),\n",
       "  (array([0.02056093, 0.9997886 , 3.297762  ], dtype=float32),\n",
       "   array([-4.67057272])),\n",
       "  (array([-0.17343631,  0.9848451 ,  3.8976035 ], dtype=float32),\n",
       "   array([-4.69264949])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.7657477])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.75077152])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-4.61129776])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-4.70046827])),\n",
       "  (array([-0.02597892,  0.9996625 ,  3.612937  ], dtype=float32),\n",
       "   array([-4.94314417])),\n",
       "  (array([-0.2344143,  0.9721368,  4.2126837], dtype=float32),\n",
       "   array([-5.06754733])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.81162464])),\n",
       "  (array([0.19632733, 0.9805384 , 2.790366  ], dtype=float32),\n",
       "   array([-4.79355076])),\n",
       "  (array([0.02881846, 0.9995847 , 3.3757699 ], dtype=float32),\n",
       "   array([-4.70878976])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.85530922])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-4.78258436])),\n",
       "  (array([0.1229858 , 0.99240845, 3.034651  ], dtype=float32),\n",
       "   array([-4.76431094])),\n",
       "  (array([-0.28071058,  0.95979244,  4.52769   ], dtype=float32),\n",
       "   array([-5.07668798])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.72697717])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-4.68612711])),\n",
       "  (array([-5.4099795e-04,  9.9999988e-01,  3.8534408e+00], dtype=float32),\n",
       "   array([-4.8862714])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-4.87034004])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-4.85803388])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-4.72708102])),\n",
       "  (array([0.33237305, 0.943148  , 1.8266664 ], dtype=float32),\n",
       "   array([-4.67068803])),\n",
       "  (array([0.217856  , 0.97598094, 2.3840275 ], dtype=float32),\n",
       "   array([-5.09757309])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.00312242])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.65828297])),\n",
       "  (array([0.23660567, 0.9716058 , 2.6486015 ], dtype=float32),\n",
       "   array([-4.70126605])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.88844658])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-4.82327131])),\n",
       "  (array([0.06013621, 0.99819016, 3.3622406 ], dtype=float32),\n",
       "   array([-4.75331736])),\n",
       "  (array([-0.13743526,  0.99051076,  3.9608831 ], dtype=float32),\n",
       "   array([-5.07722011])),\n",
       "  (array([-0.3574723,  0.9339237,  4.5537663], dtype=float32),\n",
       "   array([-5.11686967])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.93962113])),\n",
       "  (array([0.09301463, 0.9956647 , 3.337625  ], dtype=float32),\n",
       "   array([-5.10993195])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.82030237])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.81502761])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.71785088])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-4.78186222])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-4.75391002])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-4.74185792])),\n",
       "  (array([-0.22246496,  0.97494066,  4.3907266 ], dtype=float32),\n",
       "   array([-5.13065788])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.0871151])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.87339725])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-4.76549933])),\n",
       "  (array([0.31954974, 0.9475695 , 2.115075  ], dtype=float32),\n",
       "   array([-4.76885504])),\n",
       "  (array([0.19029896, 0.98172617, 2.6757522 ], dtype=float32),\n",
       "   array([-4.93793588])),\n",
       "  (array([-0.178757 ,  0.9838933,  4.161745 ], dtype=float32),\n",
       "   array([-5.15588639])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-4.82503217])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.81096137])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-4.86107839])),\n",
       "  (array([0.10564407, 0.994404  , 3.052821  ], dtype=float32),\n",
       "   array([-4.99874849])),\n",
       "  (array([-0.07651477,  0.99706846,  3.648624  ], dtype=float32),\n",
       "   array([-4.87490805])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.01525022])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.93919892])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-4.89179725])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-4.96920796])),\n",
       "  (array([-0.24896944,  0.96851134,  4.512684  ], dtype=float32),\n",
       "   array([-5.23977939])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.96137255])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.87391349])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.77735691])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-4.78355292])),\n",
       "  (array([-0.08131661,  0.9966883 ,  3.8077474 ], dtype=float32),\n",
       "   array([-5.01149098])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.18451427])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.05449141])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-4.91751401])),\n",
       "  (array([-0.01937986,  0.9998122 ,  3.8763056 ], dtype=float32),\n",
       "   array([-5.20246342])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.13050736])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.03503391])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-5.03480836])),\n",
       "  (array([-0.07308468,  0.9973257 ,  3.9289575 ], dtype=float32),\n",
       "   array([-5.27562789])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.02038745])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-5.0202427])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.97355685])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-4.98318236])),\n",
       "  (array([0.04392288, 0.99903494, 3.3734784 ], dtype=float32),\n",
       "   array([-5.19429113])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.10830726])),\n",
       "  (array([-1.6492313e-03,  9.9999863e-01,  3.6815619e+00], dtype=float32),\n",
       "   array([-5.09261347])),\n",
       "  (array([-0.21405791,  0.97682095,  4.281561  ], dtype=float32),\n",
       "   array([-5.31896671])),\n",
       "  (array([0.04744404, 0.9988739 , 3.647246  ], dtype=float32),\n",
       "   array([-5.33714672])),\n",
       "  (array([-0.16411246,  0.9864416 ,  4.2464013 ], dtype=float32),\n",
       "   array([-5.32743865])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-4.8901284])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-5.05463851])),\n",
       "  (array([0.07513285, 0.99717355, 3.242383  ], dtype=float32),\n",
       "   array([-5.16687279])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.01436984])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.9337744])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.94505547])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-4.93602976])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-4.91656139])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-4.93274954])),\n",
       "  (array([0.16891725, 0.9856302 , 2.6015127 ], dtype=float32),\n",
       "   array([-5.0414607])),\n",
       "  (array([-0.4152062 ,  0.90972733,  4.676578  ], dtype=float32),\n",
       "   array([-5.29391054])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.26177582])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.06824466])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.99591254])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-4.96628854])),\n",
       "  (array([0.23660567, 0.9716058 , 2.6486015 ], dtype=float32),\n",
       "   array([-5.11380137])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.12416898])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.07839762])),\n",
       "  (array([-0.14132921,  0.98996264,  4.412782  ], dtype=float32),\n",
       "   array([-5.36344594])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.33714046])),\n",
       "  (array([0.46169168, 0.8870405 , 1.0849779 ], dtype=float32),\n",
       "   array([-5.09344861])),\n",
       "  (array([0.27427346, 0.96165174, 2.4410865 ], dtype=float32),\n",
       "   array([-5.0987106])),\n",
       "  (array([0.12687495, 0.99191874, 3.0123253 ], dtype=float32),\n",
       "   array([-5.28075221])),\n",
       "  (array([-0.27477506,  0.9615085 ,  4.5052075 ], dtype=float32),\n",
       "   array([-5.43321011])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.18098646])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.02535358])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.06199663])),\n",
       "  (array([0.18438931, 0.9828533 , 2.710622  ], dtype=float32),\n",
       "   array([-5.17350961])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.18156231])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.15849768])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-5.10763283])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-5.09264448])),\n",
       "  (array([-0.06148719,  0.99810785,  3.6473517 ], dtype=float32),\n",
       "   array([-5.3257881])),\n",
       "  (array([-0.2704136 ,  0.96274424,  4.2459326 ], dtype=float32),\n",
       "   array([-5.412325])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.14623993])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-5.10308786])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-5.412325])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.13773737])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-5.1719624])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-5.25852776])),\n",
       "  (array([0.1540491, 0.9880632, 2.7218895], dtype=float32),\n",
       "   array([-5.1891148])),\n",
       "  (array([-0.01098163,  0.9999397 ,  3.3129368 ], dtype=float32),\n",
       "   array([-5.16762609])),\n",
       "  (array([-0.20515926,  0.9787286 ,  3.9128916 ], dtype=float32),\n",
       "   array([-5.20499182])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.28533944])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.19247982])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-5.27929435])),\n",
       "  (array([0.01335037, 0.9999109 , 3.381562  ], dtype=float32),\n",
       "   array([-5.21677771])),\n",
       "  (array([-0.18465811,  0.9828028 ,  3.9814951 ], dtype=float32),\n",
       "   array([-5.28167884])),\n",
       "  (array([-0.40241545,  0.9154571 ,  4.5685973 ], dtype=float32),\n",
       "   array([-5.46480222])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.16974478])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-5.19497107])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-5.18937798])),\n",
       "  (array([0.33237305, 0.943148  , 1.8266664 ], dtype=float32),\n",
       "   array([-5.18744385])),\n",
       "  (array([0.05628676, 0.99841464, 3.2660131 ], dtype=float32),\n",
       "   array([-5.26753856])),\n",
       "  (array([-0.13649723,  0.99064046,  3.864824  ], dtype=float32),\n",
       "   array([-5.40253882])),\n",
       "  (array([-0.352101,  0.935962,  4.457804], dtype=float32),\n",
       "   array([-5.48568734])),\n",
       "  (array([-0.06223165,  0.9980617 ,  4.171256  ], dtype=float32),\n",
       "   array([-5.43127411])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.19840556])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.07027449])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.08301597])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.14677739])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-5.0834853])),\n",
       "  (array([-0.00480571,  0.99998844,  3.4907353 ], dtype=float32),\n",
       "   array([-5.21439027])),\n",
       "  (array([-0.20781638,  0.97816783,  4.090727  ], dtype=float32),\n",
       "   array([-5.29276445])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.42740797])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.3015154])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.28872917])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.26619435])),\n",
       "  (array([0.00556235, 0.9999845 , 3.597762  ], dtype=float32),\n",
       "   array([-5.38027022])),\n",
       "  (array([-0.20290639,  0.97919816,  4.1977506 ], dtype=float32),\n",
       "   array([-5.50252278])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-5.25554016])),\n",
       "  (array([0.07751626, 0.9969911 , 3.344601  ], dtype=float32),\n",
       "   array([-5.37437658])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.36831138])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.24128082])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.30478199])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-5.41210078])),\n",
       "  (array([-0.16735658,  0.9858964 ,  4.263943  ], dtype=float32),\n",
       "   array([-5.54604298])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.19109474])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.20256208])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.23211061])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.16786496])),\n",
       "  (array([-0.05028291,  0.998735  ,  3.7974615 ], dtype=float32),\n",
       "   array([-5.36600864])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.29983296])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.27301727])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-5.22056929])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-5.23317773])),\n",
       "  (array([0.2511526, 0.9679475, 2.3486016], dtype=float32),\n",
       "   array([-5.21866945])),\n",
       "  (array([0.10743497, 0.9942121 , 2.9245622 ], dtype=float32),\n",
       "   array([-5.27726518])),\n",
       "  (array([-0.0683151,  0.9976638,  3.5202212], dtype=float32),\n",
       "   array([-5.28996568])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.49795661])),\n",
       "  (array([0.46169168, 0.8870405 , 1.0849779 ], dtype=float32),\n",
       "   array([-5.31552249])),\n",
       "  (array([0.38931558, 0.92110443, 1.6002582 ], dtype=float32),\n",
       "   array([-5.39251319])),\n",
       "  (array([0.28866684, 0.9574296 , 2.1410866 ], dtype=float32),\n",
       "   array([-5.38830703])),\n",
       "  (array([0.15672734, 0.98764193, 2.7091587 ], dtype=float32),\n",
       "   array([-5.34602705])),\n",
       "  (array([-0.00761827,  0.999971  ,  3.2998903 ], dtype=float32),\n",
       "   array([-5.41055337])),\n",
       "  (array([-0.20122835,  0.97954434,  3.8998685 ], dtype=float32),\n",
       "   array([-5.48952334])),\n",
       "  (array([-0.41399467,  0.91027933,  4.4845266 ], dtype=float32),\n",
       "   array([-5.57841842])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.32902114])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-5.33550508])),\n",
       "  (array([0.04392288, 0.99903494, 3.3734784 ], dtype=float32),\n",
       "   array([-5.44494975])),\n",
       "  (array([-0.1540844,  0.9880577,  3.9727547], dtype=float32),\n",
       "   array([-5.38370901])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.43273966])),\n",
       "  (array([0.2722778, 0.9622187, 2.4533696], dtype=float32),\n",
       "   array([-5.33125626])),\n",
       "  (array([-0.07139282,  0.99744827,  3.9192278 ], dtype=float32),\n",
       "   array([-5.48790992])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-5.35098037])),\n",
       "  (array([-0.01674634,  0.99985975,  3.6835198 ], dtype=float32),\n",
       "   array([-5.40717561])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-5.28583959])),\n",
       "  (array([0.19095115, 0.98159957, 2.967241  ], dtype=float32),\n",
       "   array([-5.28678461])),\n",
       "  (array([-0.20670803,  0.9784027 ,  4.4533625 ], dtype=float32),\n",
       "   array([-5.57600864])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.37356324])),\n",
       "  (array([0.25184932, 0.96776646, 2.6392868 ], dtype=float32),\n",
       "   array([-5.25942261])),\n",
       "  (array([0.09369749, 0.9956007 , 3.2151115 ], dtype=float32),\n",
       "   array([-5.34161344])),\n",
       "  (array([-0.32609582,  0.9453367 ,  4.7083044 ], dtype=float32),\n",
       "   array([-5.57600864])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.57263135])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.41008128])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-5.37874902])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-5.35096039])),\n",
       "  (array([0.33237305, 0.943148  , 1.8266664 ], dtype=float32),\n",
       "   array([-5.36152911])),\n",
       "  (array([0.217856  , 0.97598094, 2.3840275 ], dtype=float32),\n",
       "   array([-5.67180453])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.3814288])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.43795583])),\n",
       "  (array([0.10564407, 0.994404  , 3.052821  ], dtype=float32),\n",
       "   array([-5.38746421])),\n",
       "  (array([-0.29925415,  0.95417345,  4.5464253 ], dtype=float32),\n",
       "   array([-5.65091941])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.48276953])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-5.50577923])),\n",
       "  (array([0.06013621, 0.99819016, 3.3622406 ], dtype=float32),\n",
       "   array([-5.46964327])),\n",
       "  (array([-0.13743526,  0.99051076,  3.9608831 ], dtype=float32),\n",
       "   array([-5.62711177])),\n",
       "  (array([-0.17889006,  0.9838691 ,  4.546401  ], dtype=float32),\n",
       "   array([-5.65091941])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.50101734])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.46691556])),\n",
       "  (array([0.1546538 , 0.98796874, 3.0140913 ], dtype=float32),\n",
       "   array([-5.4471003])),\n",
       "  (array([-0.02497377,  0.9996881 ,  3.6050677 ], dtype=float32),\n",
       "   array([-5.5565982])),\n",
       "  (array([-0.23305504,  0.97246355,  4.204834  ], dtype=float32),\n",
       "   array([-5.65091941])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.58159981])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.43415334])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.41974505])),\n",
       "  (array([0.18438931, 0.9828533 , 2.710622  ], dtype=float32),\n",
       "   array([-5.46315219])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.34991827])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.33674724])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.29094927])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.27977323])),\n",
       "  (array([0.15411435, 0.988053  , 2.9015126 ], dtype=float32),\n",
       "   array([-5.32668249])),\n",
       "  (array([-0.23723324,  0.9714527 ,  4.392404  ], dtype=float32),\n",
       "   array([-5.64321592])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-5.42225396])),\n",
       "  (array([0.33395192, 0.9425901 , 2.1102986 ], dtype=float32),\n",
       "   array([-5.35384318])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.44277414])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.63061681])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.53766455])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-5.51143396])),\n",
       "  (array([0.31818897, 0.9480273 , 2.1266663 ], dtype=float32),\n",
       "   array([-5.54790499])),\n",
       "  (array([-0.21138391,  0.9774031 ,  4.474227  ], dtype=float32),\n",
       "   array([-5.73332319])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.47247205])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-5.50488711])),\n",
       "  (array([0.01335037, 0.9999109 , 3.381562  ], dtype=float32),\n",
       "   array([-5.52566147])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-5.52783386])),\n",
       "  (array([-0.01674634,  0.99985975,  3.6835198 ], dtype=float32),\n",
       "   array([-5.60554611])),\n",
       "  (array([-0.22887112,  0.97345674,  4.283415  ], dtype=float32),\n",
       "   array([-5.71243807])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.4502643])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.58781398])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-5.57417558])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-5.71243807])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.55248632])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-5.56984881])),\n",
       "  (array([0.0450341 , 0.99898547, 3.3647041 ], dtype=float32),\n",
       "   array([-5.69773326])),\n",
       "  (array([-0.37176177,  0.92832816,  4.5551653 ], dtype=float32),\n",
       "   array([-5.72893094])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.43092022])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.38970204])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.39443293])),\n",
       "  (array([-0.08029168,  0.9967714 ,  4.0989428 ], dtype=float32),\n",
       "   array([-5.52105634])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.51567589])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.71295127])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.47055042])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-5.42449247])),\n",
       "  (array([0.10876528, 0.99406743, 3.2121968 ], dtype=float32),\n",
       "   array([-5.420763])),\n",
       "  (array([-0.08131661,  0.9966883 ,  3.8077474 ], dtype=float32),\n",
       "   array([-5.53019707])),\n",
       "  (array([-0.13654359,  0.9906341 ,  4.253467  ], dtype=float32),\n",
       "   array([-5.77084217])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.57521808])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-5.49018783])),\n",
       "  (array([-0.05603496,  0.9984288 ,  3.9145865 ], dtype=float32),\n",
       "   array([-5.67690791])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.63230967])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.57358543])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-5.54517495])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-5.51492391])),\n",
       "  (array([0.13785754, 0.99045205, 2.734651  ], dtype=float32),\n",
       "   array([-5.54325207])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-5.59516686])),\n",
       "  (array([0.1755522, 0.9844701, 2.9757524], dtype=float32),\n",
       "   array([-5.54401521])),\n",
       "  (array([-1.7385861e-03,  9.9999851e-01,  3.5641048e+00], dtype=float32),\n",
       "   array([-5.62739287])),\n",
       "  (array([-0.20840491,  0.97804266,  4.1641035 ], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.48283078])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-5.48094954])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-5.54766945])),\n",
       "  (array([0.09251025, 0.99571174, 3.2245622 ], dtype=float32),\n",
       "   array([-5.45342769])),\n",
       "  (array([-0.32811782,  0.9446368 ,  4.717716  ], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([0.22181036, 0.97508985, 2.6526046 ], dtype=float32),\n",
       "   array([-5.51843669])),\n",
       "  (array([0.06193491, 0.9980802 , 3.233922  ], dtype=float32),\n",
       "   array([-5.53862775])),\n",
       "  (array([-0.12928662,  0.99160725,  3.832482  ], dtype=float32),\n",
       "   array([-5.54555008])),\n",
       "  (array([-0.34379843,  0.93904346,  4.4261875 ], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.55134307])),\n",
       "  (array([0.0787535, 0.9968941, 3.5151117], dtype=float32),\n",
       "   array([-5.64457015])),\n",
       "  (array([-0.12646443,  0.99197114,  4.112782  ], dtype=float32),\n",
       "   array([-5.66724327])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.62405647])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.45295379])),\n",
       "  (array([0.12424704, 0.99225134, 3.2047546 ], dtype=float32),\n",
       "   array([-5.57210835])),\n",
       "  (array([-0.06533164,  0.9978636 ,  3.798943  ], dtype=float32),\n",
       "   array([-5.69124103])),\n",
       "  (array([-0.28139278,  0.9595927 ,  4.397341  ], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.76459094])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.61482379])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-5.5688358])),\n",
       "  (array([0.15812863, 0.98741853, 2.9958534 ], dtype=float32),\n",
       "   array([-5.69441125])),\n",
       "  (array([-0.02052427,  0.99978936,  3.5864174 ], dtype=float32),\n",
       "   array([-5.8003377])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.6852856])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.53914635])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.5413553])),\n",
       "  (array([0.18438931, 0.9828533 , 2.710622  ], dtype=float32),\n",
       "   array([-5.65789623])),\n",
       "  (array([-0.18818893,  0.98213285,  4.1976037 ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.64837622])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.61782761])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-5.58472808])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-5.52464535])),\n",
       "  (array([-0.28482383,  0.9585799 ,  4.545933  ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.6157742])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-5.71478279])),\n",
       "  (array([-0.03174179,  0.9994961 ,  3.9835198 ], dtype=float32),\n",
       "   array([-5.72413291])),\n",
       "  (array([-0.19687444,  0.9804287 ,  4.5643654 ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.64660752])),\n",
       "  (array([0.30122933, 0.9535517 , 2.1489275 ], dtype=float32),\n",
       "   array([-5.62762381])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.74332258])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.64859557])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-5.66578427])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-5.67161033])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.52074214])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.48728016])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-5.54917657])),\n",
       "  (array([-0.08029168,  0.9967714 ,  4.0989428 ], dtype=float32),\n",
       "   array([-5.75371024])),\n",
       "  (array([-0.28128198,  0.9596252 ,  4.6965127 ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.5852276])),\n",
       "  (array([0.13911627, 0.99027604, 2.9047544 ], dtype=float32),\n",
       "   array([-5.6688681])),\n",
       "  (array([-0.25239426,  0.9676245 ,  4.396994  ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.12424704, 0.99225134, 3.2047546 ], dtype=float32),\n",
       "   array([-5.74996463])),\n",
       "  (array([-0.06533164,  0.9978636 ,  3.798943  ], dtype=float32),\n",
       "   array([-5.7586069])),\n",
       "  (array([-0.01989527,  0.99980205,  3.4925525 ], dtype=float32),\n",
       "   array([-5.68870309])),\n",
       "  (array([-0.44233072,  0.896852  ,  4.67358   ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.01019409, 0.999948  , 3.1907353 ], dtype=float32),\n",
       "   array([-5.60503601])),\n",
       "  (array([-0.17838074,  0.9839615 ,  3.7906964 ], dtype=float32),\n",
       "   array([-5.65612663])),\n",
       "  (array([-0.19311954,  0.98117524,  4.0906963 ], dtype=float32),\n",
       "   array([-5.68974278])),\n",
       "  (array([0.01019409, 0.999948  , 3.1907353 ], dtype=float32),\n",
       "   array([-5.67327483])),\n",
       "  (array([-0.40160978,  0.9158109 ,  4.6786675 ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5]))],\n",
       " [(array([-0.17838074,  0.9839615 ,  3.7906964 ], dtype=float32),\n",
       "   array([-0.6278477])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-0.66137581])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-0.68241911])),\n",
       "  (array([-0.25795427,  0.96615714,  4.583142  ], dtype=float32),\n",
       "   array([-1.25661403])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-0.88341942])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-0.7040109])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-0.68295104])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-0.67626344])),\n",
       "  (array([0.2278063, 0.9737065, 2.7669659], dtype=float32),\n",
       "   array([-0.74412858])),\n",
       "  (array([0.04744404, 0.9988739 , 3.647246  ], dtype=float32),\n",
       "   array([-0.74891542])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-0.90543606])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-0.89181323])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-0.89612191])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-0.89390858])),\n",
       "  (array([0.30530077, 0.95225596, 2.415075  ], dtype=float32),\n",
       "   array([-0.90082443])),\n",
       "  (array([-0.04725428,  0.9988829 ,  3.871256  ], dtype=float32),\n",
       "   array([-1.42292518])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-1.25661403])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.11535704])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-1.07046059])),\n",
       "  (array([-0.2849084 ,  0.95855474,  4.246425  ], dtype=float32),\n",
       "   array([-1.79232843])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-1.27603175])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-1.25113722])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-0.96778273])),\n",
       "  (array([0.07751626, 0.9969911 , 3.344601  ], dtype=float32),\n",
       "   array([-1.30982579])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-1.66519714])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.26912983])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-1.24785218])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-1.19368899])),\n",
       "  (array([-0.16913353,  0.98559314,  3.9754581 ], dtype=float32),\n",
       "   array([-1.84389112])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-1.39429074])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-1.40017507])),\n",
       "  (array([0.33395192, 0.9425901 , 2.1102986 ], dtype=float32),\n",
       "   array([-1.09687707])),\n",
       "  (array([0.19095115, 0.98159957, 2.967241  ], dtype=float32),\n",
       "   array([-1.50059738])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-1.49054626])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-1.45170738])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-1.45115951])),\n",
       "  (array([0.2893884, 0.9572118, 2.4312809], dtype=float32),\n",
       "   array([-1.73814823])),\n",
       "  (array([0.12827393, 0.9917388 , 3.2991898 ], dtype=float32),\n",
       "   array([-1.91876344])),\n",
       "  (array([-0.08093274,  0.99671954,  4.1929936 ], dtype=float32),\n",
       "   array([-2.06907354])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-1.90177611])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-1.48489593])),\n",
       "  (array([-0.34661216,  0.93800855,  4.437058  ], dtype=float32),\n",
       "   array([-2.12652512])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-1.82686286])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-1.70154384])),\n",
       "  (array([0.13785754, 0.99045205, 2.734651  ], dtype=float32),\n",
       "   array([-1.72155484])),\n",
       "  (array([-0.04306322,  0.9990724 ,  3.62749   ], dtype=float32),\n",
       "   array([-2.31852832])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.02995499])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.68059018])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-1.78624033])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-2.05145934])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-1.96315158])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.17390697])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-1.78444277])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-1.7283174])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-1.95634784])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-2.01238998])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-2.13619993])),\n",
       "  (array([-0.03174179,  0.9994961 ,  3.9835198 ], dtype=float32),\n",
       "   array([-2.49402296])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-1.97714128])),\n",
       "  (array([-0.2708653,  0.9626173,  4.118469 ], dtype=float32),\n",
       "   array([-2.46049485])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-1.99934864])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-1.97630793])),\n",
       "  (array([0.17292157, 0.9849356 , 2.6958535 ], dtype=float32),\n",
       "   array([-2.6566923])),\n",
       "  (array([-0.21301506,  0.97704893,  4.184544  ], dtype=float32),\n",
       "   array([-2.56356206])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-1.97833476])),\n",
       "  (array([0.09008144, 0.9959344 , 2.9423828 ], dtype=float32),\n",
       "   array([-2.58396355])),\n",
       "  (array([-0.10158743,  0.9948266 ,  3.8393338 ], dtype=float32),\n",
       "   array([-2.58436397])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.2673743])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-2.22838095])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-2.42208887])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-2.47252679])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-2.43356441])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-2.32852516])),\n",
       "  (array([-0.02807285,  0.9996059 ,  3.32749   ], dtype=float32),\n",
       "   array([-2.77950251])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.66691866])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-2.49983801])),\n",
       "  (array([0.2263069 , 0.97405607, 2.4816985 ], dtype=float32),\n",
       "   array([-2.70701253])),\n",
       "  (array([-0.3574723,  0.9339237,  4.5537663], dtype=float32),\n",
       "   array([-2.89271625])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-2.47217873])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-2.55861566])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-2.81885902])),\n",
       "  (array([0.14313503, 0.9897032 , 2.9991896 ], dtype=float32),\n",
       "   array([-2.60978757])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-2.68164943])),\n",
       "  (array([-0.01989527,  0.99980205,  3.4925525 ], dtype=float32),\n",
       "   array([-2.86282566])),\n",
       "  (array([-0.23723324,  0.9714527 ,  4.392404  ], dtype=float32),\n",
       "   array([-3.02807449])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-2.79486301])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-2.85997843])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-2.88231487])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-2.91527053])),\n",
       "  (array([0.03004481, 0.99954855, 3.664704  ], dtype=float32),\n",
       "   array([-3.06829162])),\n",
       "  (array([-0.19687444,  0.9804287 ,  4.5643654 ], dtype=float32),\n",
       "   array([-3.0616026])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-2.73189892])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-2.94123932])),\n",
       "  (array([-0.2225568 ,  0.97491974,  3.9271946 ], dtype=float32),\n",
       "   array([-3.12008484])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.14271941])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-2.86943133])),\n",
       "  (array([0.30122933, 0.9535517 , 2.1489275 ], dtype=float32),\n",
       "   array([-2.97613895])),\n",
       "  (array([0.1546538 , 0.98796874, 3.0140913 ], dtype=float32),\n",
       "   array([-3.13551124])),\n",
       "  (array([-0.03996572,  0.99920106,  3.9050677 ], dtype=float32),\n",
       "   array([-3.2302859])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-2.90116652])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-3.07281312])),\n",
       "  (array([-0.3776922,  0.9259312,  4.451593 ], dtype=float32),\n",
       "   array([-3.24715738])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.2776054])),\n",
       "  (array([0.217856  , 0.97598094, 2.3840275 ], dtype=float32),\n",
       "   array([-3.01705635])),\n",
       "  (array([0.05628676, 0.99841464, 3.2660131 ], dtype=float32),\n",
       "   array([-2.92067956])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-3.10465398])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-3.1796816])),\n",
       "  (array([0.34880987, 0.9371935 , 2.0997095 ], dtype=float32),\n",
       "   array([-3.04285445])),\n",
       "  (array([-0.17405279,  0.9847363 ,  4.1359544 ], dtype=float32),\n",
       "   array([-3.45629517])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.24314238])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.18925288])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.27152307])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-3.20612992])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-3.22125344])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-3.24525014])),\n",
       "  (array([0.2278063, 0.9737065, 2.7669659], dtype=float32),\n",
       "   array([-3.20819236])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.33897274])),\n",
       "  (array([0.23510137, 0.97197086, 2.3634048 ], dtype=float32),\n",
       "   array([-3.20200822])),\n",
       "  (array([0.07513285, 0.99717355, 3.242383  ], dtype=float32),\n",
       "   array([-3.66049113])),\n",
       "  (array([-0.13142811,  0.9913257 ,  4.140263  ], dtype=float32),\n",
       "   array([-3.57221846])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.58020395])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.31221205])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-3.33708722])),\n",
       "  (array([0.24108398, 0.9705043 , 2.4777367 ], dtype=float32),\n",
       "   array([-3.31595152])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-3.48956114])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-3.28044224])),\n",
       "  (array([0.22181036, 0.97508985, 2.6526046 ], dtype=float32),\n",
       "   array([-3.39506543])),\n",
       "  (array([0.0469573, 0.9988969, 3.533922 ], dtype=float32),\n",
       "   array([-3.31012987])),\n",
       "  (array([-0.17379317,  0.98478216,  4.4330945 ], dtype=float32),\n",
       "   array([-3.85003125])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.63901788])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-3.39203581])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-3.16826787])),\n",
       "  (array([-0.04105279,  0.99915695,  3.6145866 ], dtype=float32),\n",
       "   array([-3.87448917])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.58955882])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.38524318])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-3.35945724])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-3.60531726])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.83317925])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-3.41678792])),\n",
       "  (array([-0.2225568 ,  0.97491974,  3.9271946 ], dtype=float32),\n",
       "   array([-3.95884151])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.60995663])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-3.58172664])),\n",
       "  (array([-0.34661216,  0.93800855,  4.437058  ], dtype=float32),\n",
       "   array([-3.9253134])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-3.67926896])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-3.58133337])),\n",
       "  (array([0.4033289, 0.9150551, 1.5949895], dtype=float32),\n",
       "   array([-3.5657227])),\n",
       "  (array([0.2893884, 0.9572118, 2.4312809], dtype=float32),\n",
       "   array([-3.83566439])),\n",
       "  (array([-0.2865169 ,  0.95807517,  4.4913597 ], dtype=float32),\n",
       "   array([-3.97972662])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-3.53007111])),\n",
       "  (array([0.12366349, 0.99232423, 2.9121966 ], dtype=float32),\n",
       "   array([-3.83295454])),\n",
       "  (array([-0.06629246,  0.99780023,  3.8064399 ], dtype=float32),\n",
       "   array([-3.82151558])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-3.62411706])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-3.56847789])),\n",
       "  (array([-0.29685232,  0.9549234 ,  4.238388  ], dtype=float32),\n",
       "   array([-4.11123713])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.89197874])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.68298342])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-3.67338797])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-3.71847712])),\n",
       "  (array([0.0450341 , 0.99898547, 3.3647041 ], dtype=float32),\n",
       "   array([-4.0859388])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-3.97606088])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.46808372])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-3.99314799])),\n",
       "  (array([-0.1540844,  0.9880577,  3.9727547], dtype=float32),\n",
       "   array([-4.2398306])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.78265115])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.68488733])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-3.67273542])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-4.00853571])),\n",
       "  (array([-1.6492313e-03,  9.9999863e-01,  3.6815619e+00], dtype=float32),\n",
       "   array([-4.04827459])),\n",
       "  (array([-0.22868559,  0.9735003 ,  4.581561  ], dtype=float32),\n",
       "   array([-4.2398306])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-3.91275084])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-4.08860435])),\n",
       "  (array([0.10793857, 0.99415755, 3.037625  ], dtype=float32),\n",
       "   array([-4.23674329])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.06576184])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-3.9777744])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-3.96683768])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-3.90616134])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-4.02434235])),\n",
       "  (array([-0.22887112,  0.97345674,  4.283415  ], dtype=float32),\n",
       "   array([-4.27800224])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.01204383])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-3.97792142])),\n",
       "  (array([-0.3812552,  0.9244698,  4.463465 ], dtype=float32),\n",
       "   array([-4.29888735])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-3.86672892])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-3.86176176])),\n",
       "  (array([0.31954974, 0.9475695 , 2.115075  ], dtype=float32),\n",
       "   array([-4.07485856])),\n",
       "  (array([-1.7385861e-03,  9.9999851e-01,  3.5641048e+00], dtype=float32),\n",
       "   array([-4.23201579])),\n",
       "  (array([-0.22305155,  0.97480667,  4.4641037 ], dtype=float32),\n",
       "   array([-4.28703336])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.19214885])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-4.21786972])),\n",
       "  (array([0.1540491, 0.9880632, 2.7218895], dtype=float32),\n",
       "   array([-4.32311943])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-4.01775859])),\n",
       "  (array([-0.23785205,  0.9713014 ,  4.0969944 ], dtype=float32),\n",
       "   array([-4.40078166])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.1207773])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.00800522])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-4.2377018])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.34017763])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.12305461])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-4.24981589])),\n",
       "  (array([-0.05811713,  0.9983098 ,  3.6289575 ], dtype=float32),\n",
       "   array([-4.36285568])),\n",
       "  (array([-0.28071058,  0.95979244,  4.52769   ], dtype=float32),\n",
       "   array([-4.47554949])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.2029171])),\n",
       "  (array([0.23510137, 0.97197086, 2.3634048 ], dtype=float32),\n",
       "   array([-4.07842348])),\n",
       "  (array([0.07513285, 0.99717355, 3.242383  ], dtype=float32),\n",
       "   array([-4.30331])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.31831736])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-4.32273168])),\n",
       "  (array([0.02571786, 0.99966925, 3.27427   ], dtype=float32),\n",
       "   array([-4.47030329])),\n",
       "  (array([-0.18196103,  0.98330575,  4.174022  ], dtype=float32),\n",
       "   array([-4.56676006])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.25290487])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-4.31775099])),\n",
       "  (array([0.23660567, 0.9716058 , 2.6486015 ], dtype=float32),\n",
       "   array([-4.23590191])),\n",
       "  (array([-0.1432916,  0.9896805,  4.125841 ], dtype=float32),\n",
       "   array([-4.53400756])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.23205829])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.28956262])),\n",
       "  (array([0.2263069 , 0.97405607, 2.4816985 ], dtype=float32),\n",
       "   array([-4.51459288])),\n",
       "  (array([0.06013621, 0.99819016, 3.3622406 ], dtype=float32),\n",
       "   array([-4.50208647])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.42594221])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.49275569])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-4.42784334])),\n",
       "  (array([0.09246185, 0.9957162 , 3.044601  ], dtype=float32),\n",
       "   array([-4.40251156])),\n",
       "  (array([-0.10428535,  0.9945474 ,  3.9413881 ], dtype=float32),\n",
       "   array([-4.6447238])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.22225388])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.4614043])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.35903338])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.3347273])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-4.41217713])),\n",
       "  (array([-0.01674634,  0.99985975,  3.6835198 ], dtype=float32),\n",
       "   array([-4.40419273])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.59628827])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-4.3121603])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-4.62500386])),\n",
       "  (array([-0.30734912,  0.9515968 ,  4.517736  ], dtype=float32),\n",
       "   array([-4.6627365])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.4345636])),\n",
       "  (array([0.34805268, 0.93747497, 1.8102986 ], dtype=float32),\n",
       "   array([-4.40019444])),\n",
       "  (array([0.22049591, 0.9753879 , 2.6634047 ], dtype=float32),\n",
       "   array([-4.34973544])),\n",
       "  (array([0.04506031, 0.9989843 , 3.5449457 ], dtype=float32),\n",
       "   array([-4.52857933])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.664542])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-4.39575098])),\n",
       "  (array([0.30371347, 0.95276344, 2.131281  ], dtype=float32),\n",
       "   array([-4.49655628])),\n",
       "  (array([0.15812863, 0.98741853, 2.9958534 ], dtype=float32),\n",
       "   array([-4.70380638])),\n",
       "  (array([-0.03551824,  0.999369  ,  3.8864174 ], dtype=float32),\n",
       "   array([-4.81892036])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.67663968])),\n",
       "  (array([0.12054769, 0.99270755, 2.752821  ], dtype=float32),\n",
       "   array([-4.51430127])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.45455044])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-4.54172116])),\n",
       "  (array([0.22181036, 0.97508985, 2.6526046 ], dtype=float32),\n",
       "   array([-4.68343406])),\n",
       "  (array([-0.17379317,  0.98478216,  4.4330945 ], dtype=float32),\n",
       "   array([-4.83682341])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.58450585])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.56263038])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.53287169])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.78743107])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.71417434])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.47530743])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-4.64334663])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-4.58223676])),\n",
       "  (array([0.03004481, 0.99954855, 3.664704  ], dtype=float32),\n",
       "   array([-4.74909956])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.55458831])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-4.61510288])),\n",
       "  (array([-0.20840491,  0.97804266,  4.1641035 ], dtype=float32),\n",
       "   array([-4.87428957])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-4.49425437])),\n",
       "  (array([0.26633695, 0.96388   , 2.3392868 ], dtype=float32),\n",
       "   array([-4.43969391])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.65992602])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-4.72921916])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-4.6686274])),\n",
       "  (array([0.07751626, 0.9969911 , 3.344601  ], dtype=float32),\n",
       "   array([-4.76061051])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.89574614])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-4.62383226])),\n",
       "  (array([-0.38815582,  0.9215938 ,  4.4862375 ], dtype=float32),\n",
       "   array([-5.06754733])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-4.75313679])),\n",
       "  (array([0.1540491, 0.9880632, 2.7218895], dtype=float32),\n",
       "   array([-4.78083963])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.76774315])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.71428586])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-4.72651362])),\n",
       "  (array([-0.16913353,  0.98559314,  3.9754581 ], dtype=float32),\n",
       "   array([-5.06754733])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-4.95054874])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.75360591])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-4.7108687])),\n",
       "  (array([-0.05811713,  0.9983098 ,  3.6289575 ], dtype=float32),\n",
       "   array([-4.9095621])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.71727728])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-4.71655547])),\n",
       "  (array([0.33395192, 0.9425901 , 2.1102986 ], dtype=float32),\n",
       "   array([-4.78219942])),\n",
       "  (array([0.19095115, 0.98159957, 2.967241  ], dtype=float32),\n",
       "   array([-4.69364655])),\n",
       "  (array([-0.22136408,  0.97519124,  4.4534407 ], dtype=float32),\n",
       "   array([-5.04315987])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-4.92852366])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.81846484])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-4.73817089])),\n",
       "  (array([0.07742796, 0.99699795, 3.227306  ], dtype=float32),\n",
       "   array([-4.90934144])),\n",
       "  (array([-0.1283918 ,  0.99172354,  4.1250544 ], dtype=float32),\n",
       "   array([-5.08334156])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-4.84334628])),\n",
       "  (array([0.2263069 , 0.97405607, 2.4816985 ], dtype=float32),\n",
       "   array([-4.83782804])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-4.90423308])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.74967482])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-4.79038463])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-4.97317715])),\n",
       "  (array([-0.03174179,  0.9994961 ,  3.9835198 ], dtype=float32),\n",
       "   array([-5.11686967])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.03115411])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-4.96570173])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-4.94895674])),\n",
       "  (array([0.25711006, 0.96638215, 2.4628384 ], dtype=float32),\n",
       "   array([-4.8652921])),\n",
       "  (array([-0.10338435,  0.9946415 ,  3.9343736 ], dtype=float32),\n",
       "   array([-5.16418599])),\n",
       "  (array([0.16891725, 0.9856302 , 2.6015127 ], dtype=float32),\n",
       "   array([-4.77977214])),\n",
       "  (array([-0.00480571,  0.99998844,  3.4907353 ], dtype=float32),\n",
       "   array([-4.92913606])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-4.84147393])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-4.79746215])),\n",
       "  (array([0.02836051, 0.9995978 , 3.2620468 ], dtype=float32),\n",
       "   array([-5.05119417])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.93608315])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-4.92006003])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-4.94103495])),\n",
       "  (array([-1.6492313e-03,  9.9999863e-01,  3.6815619e+00], dtype=float32),\n",
       "   array([-4.96920663])),\n",
       "  (array([-0.22868559,  0.9735003 ,  4.581561  ], dtype=float32),\n",
       "   array([-5.1894145])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.06097773])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-4.90390199])),\n",
       "  (array([-0.2849084 ,  0.95855474,  4.246425  ], dtype=float32),\n",
       "   array([-5.1894145])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.10703482])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-4.97373507])),\n",
       "  (array([0.1540491, 0.9880632, 2.7218895], dtype=float32),\n",
       "   array([-5.015298])),\n",
       "  (array([-0.02597892,  0.9996625 ,  3.612937  ], dtype=float32),\n",
       "   array([-5.16527823])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-4.72798842])),\n",
       "  (array([0.26633695, 0.96388   , 2.3392868 ], dtype=float32),\n",
       "   array([-4.99922441])),\n",
       "  (array([-0.29711488,  0.95484173,  4.4052634 ], dtype=float32),\n",
       "   array([-5.20625129])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.09810833])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-4.94651968])),\n",
       "  (array([0.31818897, 0.9480273 , 2.1266663 ], dtype=float32),\n",
       "   array([-4.96632827])),\n",
       "  (array([0.17355095, 0.9848249 , 2.9876869 ], dtype=float32),\n",
       "   array([-5.02657723])),\n",
       "  (array([-0.24079931,  0.9705749 ,  4.476165  ], dtype=float32),\n",
       "   array([-5.27859226])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.17510101])),\n",
       "  (array([0.27157632, 0.9624169 , 2.1628385 ], dtype=float32),\n",
       "   array([-5.06032842])),\n",
       "  (array([0.1229858 , 0.99240845, 3.034651  ], dtype=float32),\n",
       "   array([-5.20814231])),\n",
       "  (array([-0.2950401 ,  0.95548487,  4.526952  ], dtype=float32),\n",
       "   array([-5.31896671])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-4.94333278])),\n",
       "  (array([0.0450341 , 0.99898547, 3.3647041 ], dtype=float32),\n",
       "   array([-5.11233089])),\n",
       "  (array([-0.16735658,  0.9858964 ,  4.263943  ], dtype=float32),\n",
       "   array([-5.31896671])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-4.99183798])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-5.15072392])),\n",
       "  (array([-0.1540844,  0.9880577,  3.9727547], dtype=float32),\n",
       "   array([-5.31896671])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.15402999])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.08942983])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.00390476])),\n",
       "  (array([0.18141866, 0.98340595, 2.7940075 ], dtype=float32),\n",
       "   array([-4.99160432])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.27883243])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.07616957])),\n",
       "  (array([0.35991094, 0.9329867 , 1.917226  ], dtype=float32),\n",
       "   array([-5.05560589])),\n",
       "  (array([0.2278063, 0.9737065, 2.7669659], dtype=float32),\n",
       "   array([-5.13689296])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.02417503])),\n",
       "  (array([0.23510137, 0.97197086, 2.3634048 ], dtype=float32),\n",
       "   array([-5.06011984])),\n",
       "  (array([-0.11654399,  0.9931855 ,  3.8402631 ], dtype=float32),\n",
       "   array([-5.29391054])),\n",
       "  (array([0.01019409, 0.999948  , 3.1907353 ], dtype=float32),\n",
       "   array([-5.13757914])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-4.99969362])),\n",
       "  (array([0.362828  , 0.93185616, 1.7997096 ], dtype=float32),\n",
       "   array([-5.01460905])),\n",
       "  (array([0.07742796, 0.99699795, 3.227306  ], dtype=float32),\n",
       "   array([-5.19465261])),\n",
       "  (array([-0.35665926,  0.93423456,  4.718847  ], dtype=float32),\n",
       "   array([-5.36344594])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.11205447])),\n",
       "  (array([0.25184932, 0.96776646, 2.6392868 ], dtype=float32),\n",
       "   array([-5.01858625])),\n",
       "  (array([0.0787535, 0.9968941, 3.5151117], dtype=float32),\n",
       "   array([-5.14383275])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.17845708])),\n",
       "  (array([0.38931558, 0.92110443, 1.6002582 ], dtype=float32),\n",
       "   array([-5.12335748])),\n",
       "  (array([-0.05307044,  0.99859077,  3.6062644 ], dtype=float32),\n",
       "   array([-5.34808634])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-5.11646505])),\n",
       "  (array([0.02056093, 0.9997886 , 3.297762  ], dtype=float32),\n",
       "   array([-5.32310225])),\n",
       "  (array([-0.18818893,  0.98213285,  4.1976037 ], dtype=float32),\n",
       "   array([-5.412325])),\n",
       "  (array([0.12054769, 0.99270755, 2.752821  ], dtype=float32),\n",
       "   array([-5.26872671])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.24186266])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.19563407])),\n",
       "  (array([-0.41820955,  0.9083506 ,  4.496938  ], dtype=float32),\n",
       "   array([-5.412325])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.15459304])),\n",
       "  (array([0.30122933, 0.9535517 , 2.1489275 ], dtype=float32),\n",
       "   array([-5.28027362])),\n",
       "  (array([0.1546538 , 0.98796874, 3.0140913 ], dtype=float32),\n",
       "   array([-5.2449971])),\n",
       "  (array([-0.03996572,  0.99920106,  3.9050677 ], dtype=float32),\n",
       "   array([-5.412325])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.3790522])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.16489009])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.25885234])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.27679293])),\n",
       "  (array([0.217856  , 0.97598094, 2.3840275 ], dtype=float32),\n",
       "   array([-5.27799535])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.23972148])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-5.17539189])),\n",
       "  (array([0.41778684, 0.9085451 , 1.5836663 ], dtype=float32),\n",
       "   array([-5.20564323])),\n",
       "  (array([0.30530077, 0.95225596, 2.415075  ], dtype=float32),\n",
       "   array([-5.19004036])),\n",
       "  (array([0.14576967, 0.98931855, 3.279267  ], dtype=float32),\n",
       "   array([-5.19371204])),\n",
       "  (array([0.16891725, 0.9856302 , 2.6015127 ], dtype=float32),\n",
       "   array([-5.1342697])),\n",
       "  (array([-0.42870572,  0.9034442 ,  4.6743526 ], dtype=float32),\n",
       "   array([-5.43127411])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.16129952])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-5.20806836])),\n",
       "  (array([0.22181036, 0.97508985, 2.6526046 ], dtype=float32),\n",
       "   array([-5.21892149])),\n",
       "  (array([0.0469573, 0.9988969, 3.533922 ], dtype=float32),\n",
       "   array([-5.23293948])),\n",
       "  (array([-0.17379317,  0.98478216,  4.4330945 ], dtype=float32),\n",
       "   array([-5.46899467])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.30977688])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.29299174])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-5.24943497])),\n",
       "  (array([0.19632733, 0.9805384 , 2.790366  ], dtype=float32),\n",
       "   array([-5.30099937])),\n",
       "  (array([0.01382201, 0.99990445, 3.6757698 ], dtype=float32),\n",
       "   array([-5.3167418])),\n",
       "  (array([-0.21331075,  0.9769844 ,  4.575698  ], dtype=float32),\n",
       "   array([-5.50252278])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-5.28707693])),\n",
       "  (array([0.18438931, 0.9828533 , 2.710622  ], dtype=float32),\n",
       "   array([-5.34809964])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.22992842])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.19181406])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-5.25641433])),\n",
       "  (array([-0.11923873,  0.9928656 ,  3.9423442 ], dtype=float32),\n",
       "   array([-5.50252278])),\n",
       "  (array([0.37386474, 0.92748326, 1.617226  ], dtype=float32),\n",
       "   array([-5.36378707])),\n",
       "  (array([0.25711006, 0.96638215, 2.4628384 ], dtype=float32),\n",
       "   array([-5.30313031])),\n",
       "  (array([0.09301463, 0.9956647 , 3.337625  ], dtype=float32),\n",
       "   array([-5.38897237])),\n",
       "  (array([-0.11829177,  0.9929789 ,  4.2343736 ], dtype=float32),\n",
       "   array([-5.50252278])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.440175])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.35710414])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-5.35294626])),\n",
       "  (array([0.0450341 , 0.99898547, 3.3647041 ], dtype=float32),\n",
       "   array([-5.47786712])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.19052181])),\n",
       "  (array([0.13911627, 0.99027604, 2.9047544 ], dtype=float32),\n",
       "   array([-5.29265579])),\n",
       "  (array([-0.2668565,  0.9637363,  4.396513 ], dtype=float32),\n",
       "   array([-5.51251487])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.26174071])),\n",
       "  (array([-0.2708653,  0.9626173,  4.118469 ], dtype=float32),\n",
       "   array([-5.51251487])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.35976487])),\n",
       "  (array([0.50910985, 0.86070156, 0.28945172], dtype=float32),\n",
       "   array([-5.3640793])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.42506837])),\n",
       "  (array([0.21101277, 0.97748333, 2.490366  ], dtype=float32),\n",
       "   array([-5.41849123])),\n",
       "  (array([-0.3736033,  0.9275886,  4.563798 ], dtype=float32),\n",
       "   array([-5.55753331])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.49285605])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.45982474])),\n",
       "  (array([0.3879699 , 0.92167205, 1.6121156 ], dtype=float32),\n",
       "   array([-5.40074636])),\n",
       "  (array([0.12418634, 0.9922589 , 3.0250337 ], dtype=float32),\n",
       "   array([-5.39166342])),\n",
       "  (array([-0.2929582 ,  0.95612526,  4.517314  ], dtype=float32),\n",
       "   array([-5.60494625])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.54393734])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.39434292])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.25017675])),\n",
       "  (array([-0.22887112,  0.97345674,  4.283415  ], dtype=float32),\n",
       "   array([-5.60953675])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.32350707])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-5.28685621])),\n",
       "  (array([0.33395192, 0.9425901 , 2.1102986 ], dtype=float32),\n",
       "   array([-5.23828101])),\n",
       "  (array([0.0144585 , 0.99989545, 3.5534408 ], dtype=float32),\n",
       "   array([-5.36074992])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.23298525])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-5.23183385])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.42419316])),\n",
       "  (array([0.2556139 , 0.96677893, 2.1777368 ], dtype=float32),\n",
       "   array([-5.34391071])),\n",
       "  (array([-0.07651477,  0.99706846,  3.648624  ], dtype=float32),\n",
       "   array([-5.46397073])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.50466173])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.43456724])),\n",
       "  (array([0.2263069 , 0.97405607, 2.4816985 ], dtype=float32),\n",
       "   array([-5.52628912])),\n",
       "  (array([-0.3574723,  0.9339237,  4.5537663], dtype=float32),\n",
       "   array([-5.65091941])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.52325985])),\n",
       "  (array([0.2278063, 0.9737065, 2.7669659], dtype=float32),\n",
       "   array([-5.36705716])),\n",
       "  (array([0.04744404, 0.9988739 , 3.647246  ], dtype=float32),\n",
       "   array([-5.52405159])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.41362206])),\n",
       "  (array([0.30122933, 0.9535517 , 2.1489275 ], dtype=float32),\n",
       "   array([-5.39706056])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.61229141])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-5.42219943])),\n",
       "  (array([0.02056093, 0.9997886 , 3.297762  ], dtype=float32),\n",
       "   array([-5.5383077])),\n",
       "  (array([-0.18818893,  0.98213285,  4.1976037 ], dtype=float32),\n",
       "   array([-5.67674403])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-5.32759405])),\n",
       "  (array([-0.01989527,  0.99980205,  3.4925525 ], dtype=float32),\n",
       "   array([-5.52290602])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.45438882])),\n",
       "  (array([0.20565312, 0.97862494, 2.667241  ], dtype=float32),\n",
       "   array([-5.46035268])),\n",
       "  (array([0.02956624, 0.9995628 , 3.55121   ], dtype=float32),\n",
       "   array([-5.5040153])),\n",
       "  (array([-0.1917781 ,  0.98143834,  4.450882  ], dtype=float32),\n",
       "   array([-5.64321592])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.39442564])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-5.35851105])),\n",
       "  (array([0.2071596, 0.9783072, 2.9526045], dtype=float32),\n",
       "   array([-5.33841691])),\n",
       "  (array([0.01685313, 0.99985796, 3.836335  ], dtype=float32),\n",
       "   array([-5.29363402])),\n",
       "  (array([-0.21818814,  0.9759067 ,  4.7362285 ], dtype=float32),\n",
       "   array([-5.64321592])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.5730533])),\n",
       "  (array([0.41700885, 0.9089024 , 1.2949896 ], dtype=float32),\n",
       "   array([-5.47022298])),\n",
       "  (array([0.18830325, 0.9821109 , 2.687687  ], dtype=float32),\n",
       "   array([-5.58226388])),\n",
       "  (array([0.01072049, 0.99994254, 3.57427   ], dtype=float32),\n",
       "   array([-5.66213904])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.36764774])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-5.43917525])),\n",
       "  (array([-0.03174179,  0.9994961 ,  3.9835198 ], dtype=float32),\n",
       "   array([-5.71243807])),\n",
       "  (array([-0.18465811,  0.9828028 ,  3.9814951 ], dtype=float32),\n",
       "   array([-5.71243807])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.49225877])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.47725814])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.45749483])),\n",
       "  (array([0.33077928, 0.9437081 , 1.9325849 ], dtype=float32),\n",
       "   array([-5.50000597])),\n",
       "  (array([0.19632733, 0.9805384 , 2.790366  ], dtype=float32),\n",
       "   array([-5.57451602])),\n",
       "  (array([0.01382201, 0.99990445, 3.6757698 ], dtype=float32),\n",
       "   array([-5.61364631])),\n",
       "  (array([-0.21331075,  0.9769844 ,  4.575698  ], dtype=float32),\n",
       "   array([-5.71243807])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.57312115])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.56661368])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.67718484])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.58261804])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-5.55597974])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.36122899])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.36123926])),\n",
       "  (array([0.12424704, 0.99225134, 3.2047546 ], dtype=float32),\n",
       "   array([-5.42305928])),\n",
       "  (array([-0.3100107 ,  0.95073307,  4.6965218 ], dtype=float32),\n",
       "   array([-5.69540283])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.3807808])),\n",
       "  (array([0.37699988, 0.9262133 , 1.7946267 ], dtype=float32),\n",
       "   array([-5.49053922])),\n",
       "  (array([0.09369749, 0.9956007 , 3.2151115 ], dtype=float32),\n",
       "   array([-5.52876154])),\n",
       "  (array([-0.11152299,  0.99376184,  4.111812  ], dtype=float32),\n",
       "   array([-5.69540283])),\n",
       "  (array([0.26633695, 0.96388   , 2.3392868 ], dtype=float32),\n",
       "   array([-5.45815748])),\n",
       "  (array([-0.29711488,  0.95484173,  4.4052634 ], dtype=float32),\n",
       "   array([-5.73731406])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.65861349])),\n",
       "  (array([0.35916167, 0.93327534, 1.6277802 ], dtype=float32),\n",
       "   array([-5.60676552])),\n",
       "  (array([0.07562959, 0.997136  , 3.355615  ], dtype=float32),\n",
       "   array([-5.62514172])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-5.4860093])),\n",
       "  (array([0.13921139, 0.9902627 , 3.0218894 ], dtype=float32),\n",
       "   array([-5.5715619])),\n",
       "  (array([-0.2780224 ,  0.96057457,  4.513408  ], dtype=float32),\n",
       "   array([-5.77084217])),\n",
       "  (array([-0.02807285,  0.9996059 ,  3.32749   ], dtype=float32),\n",
       "   array([-5.6656901])),\n",
       "  (array([-0.237155  ,  0.97147185,  4.2271943 ], dtype=float32),\n",
       "   array([-5.77084217])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.73045451])),\n",
       "  (array([0.49589095, 0.86838484, 0.2952465 ], dtype=float32),\n",
       "   array([-5.65650557])),\n",
       "  (array([0.44755894, 0.89425445, 1.0965351 ], dtype=float32),\n",
       "   array([-5.61579301])),\n",
       "  (array([0.24238572, 0.97018   , 2.466966  ], dtype=float32),\n",
       "   array([-5.70388773])),\n",
       "  (array([0.07751626, 0.9969911 , 3.344601  ], dtype=float32),\n",
       "   array([-5.66441697])),\n",
       "  (array([-0.13411775,  0.9909654 ,  4.2423444 ], dtype=float32),\n",
       "   array([-5.80303195])),\n",
       "  (array([0.48834422, 0.8726511 , 0.77917796], dtype=float32),\n",
       "   array([-5.51333127])),\n",
       "  (array([0.31954974, 0.9475695 , 2.115075  ], dtype=float32),\n",
       "   array([-5.45138945])),\n",
       "  (array([-0.09826574,  0.9951602 ,  3.821346  ], dtype=float32),\n",
       "   array([-5.62888193])),\n",
       "  (array([ 0.5219626 ,  0.8529684 , -0.01054829], dtype=float32),\n",
       "   array([-5.55870299])),\n",
       "  (array([0.43136752, 0.9021763 , 1.2836663 ], dtype=float32),\n",
       "   array([-5.50535272])),\n",
       "  (array([0.33395192, 0.9425901 , 2.1102986 ], dtype=float32),\n",
       "   array([-5.50589821])),\n",
       "  (array([0.19095115, 0.98159957, 2.967241  ], dtype=float32),\n",
       "   array([-5.52825674])),\n",
       "  (array([-5.4099795e-04,  9.9999988e-01,  3.8534408e+00], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([0.50137854, 0.865228  , 0.47917798], dtype=float32),\n",
       "   array([-5.55339551])),\n",
       "  (array([0.4451004, 0.8954807, 1.2780991], dtype=float32),\n",
       "   array([-5.54498428])),\n",
       "  (array([0.45848206, 0.88870364, 0.978099  ], dtype=float32),\n",
       "   array([-5.56933299])),\n",
       "  (array([0.25184932, 0.96776646, 2.6392868 ], dtype=float32),\n",
       "   array([-5.52279518])),\n",
       "  (array([-0.35427812,  0.93514013,  4.7067604 ], dtype=float32),\n",
       "   array([-5.76950384])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.51309056])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.48832773])),\n",
       "  (array([ 0.5215126 ,  0.8532435 , -0.50048095], dtype=float32),\n",
       "   array([-5.67052557])),\n",
       "  (array([0.47494483, 0.88001555, 0.7849779 ], dtype=float32),\n",
       "   array([-5.60280945])),\n",
       "  (array([0.30371347, 0.95276344, 2.131281  ], dtype=float32),\n",
       "   array([-5.6236989])),\n",
       "  (array([-0.22782046,  0.97370315,  4.1862593 ], dtype=float32),\n",
       "   array([-5.83966998])),\n",
       "  (array([0.31549817, 0.9489262 , 1.8489274 ], dtype=float32),\n",
       "   array([-5.57821277])),\n",
       "  (array([0.02056093, 0.9997886 , 3.297762  ], dtype=float32),\n",
       "   array([-5.78311628])),\n",
       "  (array([0.12054769, 0.99270755, 2.752821  ], dtype=float32),\n",
       "   array([-5.57234487])),\n",
       "  (array([-0.06148719,  0.99810785,  3.6473517 ], dtype=float32),\n",
       "   array([-5.72003023])),\n",
       "  (array([0.42028418, 0.90739256, 1.4020405 ], dtype=float32),\n",
       "   array([-5.58660065])),\n",
       "  (array([0.01335037, 0.9999109 , 3.381562  ], dtype=float32),\n",
       "   array([-5.74568312])),\n",
       "  (array([-0.19937883,  0.9799225 ,  4.281495  ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([0.48280987, 0.8757252 , 0.5952465 ], dtype=float32),\n",
       "   array([-5.68931639])),\n",
       "  (array([0.316587  , 0.94856346, 2.2325847 ], dtype=float32),\n",
       "   array([-5.55663353])),\n",
       "  (array([0.16664772, 0.9860165 , 3.0940075 ], dtype=float32),\n",
       "   array([-5.63901933])),\n",
       "  (array([-0.25795427,  0.96615714,  4.583142  ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([ 0.5086558 ,  0.86096996, -0.20048095], dtype=float32),\n",
       "   array([-5.74491441])),\n",
       "  (array([0.43384728, 0.90098643, 1.1020404 ], dtype=float32),\n",
       "   array([-5.66175758])),\n",
       "  (array([0.34512267, 0.93855757, 1.9277803 ], dtype=float32),\n",
       "   array([-5.64620152])),\n",
       "  (array([0.21167116, 0.97734094, 2.7816985 ], dtype=float32),\n",
       "   array([-5.67830427])),\n",
       "  (array([0.03004481, 0.99954855, 3.664704  ], dtype=float32),\n",
       "   array([-5.73182133])),\n",
       "  (array([0.40175083, 0.915749  , 1.3121157 ], dtype=float32),\n",
       "   array([-5.60314432])),\n",
       "  (array([0.16945538, 0.9855379 , 2.7140913 ], dtype=float32),\n",
       "   array([-5.69330311])),\n",
       "  (array([-0.00988504,  0.9999511 ,  3.6032445 ], dtype=float32),\n",
       "   array([-5.76911863])),\n",
       "  (array([-0.23288734,  0.9725037 ,  4.503208  ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([0.19911082, 0.97997695, 2.4106221 ], dtype=float32),\n",
       "   array([-5.66381625])),\n",
       "  (array([-0.15841596,  0.98737246,  3.8951278 ], dtype=float32),\n",
       "   array([-5.81878486])),\n",
       "  (array([ 0.5      ,  0.8660254, -1.       ], dtype=float32),\n",
       "   array([-5.83036612])),\n",
       "  (array([0.46092188, 0.8874407 , 0.79653513], dtype=float32),\n",
       "   array([-5.63024123])),\n",
       "  (array([0.2866799, 0.9580264, 2.1533697], dtype=float32),\n",
       "   array([-5.67578152])),\n",
       "  (array([0.13921139, 0.9902627 , 3.0218894 ], dtype=float32),\n",
       "   array([-5.70964464])),\n",
       "  (array([-0.05603496,  0.9984288 ,  3.9145865 ], dtype=float32),\n",
       "   array([-5.84950765])),\n",
       "  (array([0.16891725, 0.9856302 , 2.6015127 ], dtype=float32),\n",
       "   array([-5.61733153])),\n",
       "  (array([-0.00480571,  0.99998844,  3.4907353 ], dtype=float32),\n",
       "   array([-5.6635941])),\n",
       "  (array([-0.22246496,  0.97494066,  4.3907266 ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.56734266])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.58156698])),\n",
       "  (array([0.12424704, 0.99225134, 3.2047546 ], dtype=float32),\n",
       "   array([-5.6411736])),\n",
       "  (array([-0.3100107 ,  0.95073307,  4.6965218 ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.13911627, 0.99027604, 2.9047544 ], dtype=float32),\n",
       "   array([-5.68558687])),\n",
       "  (array([-0.05028291,  0.998735  ,  3.7974615 ], dtype=float32),\n",
       "   array([-5.72400723])),\n",
       "  (array([-0.03529679,  0.9993769 ,  3.4974616 ], dtype=float32),\n",
       "   array([-5.76623509])),\n",
       "  (array([0.39085016, 0.9204543 , 1.4946268 ], dtype=float32),\n",
       "   array([-5.65125798])),\n",
       "  (array([0.2809719 , 0.95971596, 2.3349676 ], dtype=float32),\n",
       "   array([-5.64274521])),\n",
       "  (array([-0.28139278,  0.9595927 ,  4.397341  ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.2953355, 0.9553936, 2.0349674], dtype=float32),\n",
       "   array([-5.70192067])),\n",
       "  (array([-0.38782793,  0.92173177,  4.3786674 ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([0.01019409, 0.999948  , 3.1907353 ], dtype=float32),\n",
       "   array([-5.68531637])),\n",
       "  (array([-0.4152062 ,  0.90972733,  4.676578  ], dtype=float32),\n",
       "   array([-5.81597954])),\n",
       "  (array([-0.17838074,  0.9839615 ,  3.7906964 ], dtype=float32),\n",
       "   array([-5.78085983])),\n",
       "  (array([-0.17838074,  0.9839615 ,  3.7906964 ], dtype=float32),\n",
       "   array([-5.8351551])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5])),\n",
       "  (array([0, 0, 0]), array([-5]))]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c386eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ref)\n",
    "for i in range(50):\n",
    "    plt.plot(euclids[i])\n",
    "plt.axhline(y=0.5, color='g', linestyle='--')\n",
    "plt.axhline(y=0, color='g', linestyle='--')\n",
    "plt.plot()\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Euclidean distance to target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a89d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "np.save('q_tab_pen_asap_, reward_q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf437f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
